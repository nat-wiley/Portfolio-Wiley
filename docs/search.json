[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Bison_storymap.html",
    "href": "Bison_storymap.html",
    "title": "COP27 Presentation - SDG 15 & Soapstone Bison",
    "section": "",
    "text": "This story map covers a case study of Sustainable Development Goal (SDG) 15, focusing on the Soapstone Bison reintroduction in Northern Colorado. I had the pleasure of presenting our case study for the YEAH Network in Sharm El- Sheikh, Egypt in front of global leaders to address climate impacts.\n\nSDG 15 is Life on Land\n\nA Success Story of Soapstone Bison - ArcGIS Story Map"
  },
  {
    "objectID": "COB_report.html",
    "href": "COB_report.html",
    "title": "College of Business Sustainability Report",
    "section": "",
    "text": "This is a sustainability report I prepared during an internship for the College of Business at Colorado State University. During this internship, I conducted a greenhouse gas analysis for their fiscal year operations for 2019 and 2021 to reflect a covid19 and non-covid19 year. This sustainability report led to the formation of a green team where they are currently implementing recommendations I made for them to reduce their operational emissions.\nThe PDF of my report is available to view on my LinkedIn through the link below:\nLink to view sustainability report"
  },
  {
    "objectID": "Datagaps.html",
    "href": "Datagaps.html",
    "title": "Addressing Data Gaps",
    "section": "",
    "text": "This project used good practice to ensure consistent activity data when conducting greenhouse gas inventories and resolving data gaps. Several different methods were applied including:\n\nOverlap method\nSurrogate data method\nSimple linear interpolation and extrapolation\nRegression models\n\n\nOverlap method R Script\nThis project used the IPCC 2006 guidelines overlap method to recalculate the emission estimates from 1990-1999, approximating the values for a Tier 2 method.\n\n# Overlap Method\n#\n# Tier 1 direct N2O estimates (MMT CO2 eq) from 1990-1999\nT1.recalc = c(90.50, 87.16, 88.38, 93.16, 87.92, 89.76, 89.40, 90.27, 96.25, 88.48)\n\n# Tier 1 direct N2O estimates (MMT CO2 eq) from 2000-2012\n\nT1.overlap = c(91.33, 93.52, 90.61, 93.74, 99.11, 93.96, 92.45, 98.76, 96.81, 99.33, 103.28, 95.28, 90.87)\n\n# Tier 3 direct N2O estimates (MMT CO2 eq) from 2000-2012\nT3.overlap = c(136.90, 138.81, 137.03, 139.09, 145.45, 139.32, 139.66, 145.63, 142.38, 145.48, 149.44, 142.33, 139.73)\n\n\nn = 2012 #last year in the overlap period\nm = 2000 #first year in overlap period\n\n# calculate the value inside the parentheses from equation 5.1 in IPCC GL CH 5\nvalIP = 1 / (n - m + 1)*sum (T3.overlap/T1.overlap)\nvalIP\n\n# Tier estimates for 1990 - 1999 using overlap method, (looking at this because we are filling in the table that has the missing values in part 2 of hw)\nT3.recalc = T1.recalc * valIP\n\n# complete Tier 1 direct N2O estimates (MMT CO2 eq) from 1990 - 2012\nT1.1990.2012 = c(T1.recalc, T1.overlap)\n\n# Actual Tier 3 estimates using DAYCENT for 1990-1999\nT3.actual = c(135.81, 134.32, 134.61, 134.77, 132.02, 133.34, 134.14, 133.32, 140.36, 133.08)\n\n# complete Tier 3 direct N2O estimates (MMT CO2 eq) from 1990-2012\nT3.1990.2012 = c(T3.actual, T3.overlap)\n\n\n# graph values \nyears = 1990:2012\nyears.recalc = 1990:1999\nplot (x = years, y = T1.1990.2012, type = \"l\", lwd = 4, col = \"chartreuse\",\n      xlim = c(1990,2012), xlab = \"Year\", ylim = c(0,160),\n      ylab = \"N2O Emissions (MMT CO2 Eq)\", main = \"Direct N2O Emissions from US cropland (MMT CO2-eq) \\n\n      Overlap - Consistent Relationship\")\nlines (x = years, y= T3.1990.2012, lty = 1, lwd = 4, col = \"lightblue\")\nlines ( x= years.recalc, y = T3.recalc, lty = 2, lwd = 4, col = \"darkgreen\")\n\nlegend(\"bottomleft\", c(\"Tier-1 Method\", \"Tier-3 Method\", \"Splice\"),\n       lwd = c(4,4,4),  lty = c(1,1,2), \n       col = c(\"chartreuse\", \"lightblue\", \"darkgreen\"))\n\n\n\nSurrogate Data Method R Script\n2005-2012 data was provided for direct N2O emissions using a Tier 3 method. We assumed that N2O emission estimates were missing for 2007 and 2008.\n\n\n# Part 3: Surrogate Data Method (the simple version, the surrogate data helps us to approximate missing emissions estimates)\n\n# Q6 on hw\nT3.2008 = 145.48*(20.67/21.21) #145.48 were the emissions in 2009 in the chart and adjusting it based on the ratio of the fertilizer (N inputs) in 2009\n\n# Q7 on hw\nT3.2007 = 139.66*(21.09/19.74)\n\n\n\nSimple Linear Interpolation and Extrapolation R Script\nThis R script contains a simple linear model associated with BTUs from coal production.\n\n# Part 4: Simple Linear Interpolation/Extrapolation\n# Trend extrapolation, extending the time series\n\nyear.2010 = 2000:2010\ncoal = c(90.54, 94.7, 95.43, 102.65, 110.95, 118.28, 125.76, 131.11, 135.47, 138.4, 147.96)\nlm.fit <- lm(coal~year.2010)\nsummary(lm.fit)\n#when looking at the model output from the summary: for every year, \n      #we are going up by ~6 Quadrillion BTUs on avg based on this linear model)\n\n# Q11 on hw\ncoal.2011.2014.extrapolated <- lm.fit$coefficients[1]+\n                                lm.fit$coefficients[2]*(2011:2014)\ncoal.2011.2014.actual <- c(157.99, 163.02, 164.02, 163.81)\n\n#the [1], [2] mean there is a coefficient for the intercept and the time. So first I want to pull out the intercept [1], and then time [2]\n\ncoal.2000.2014  <- c(coal,coal.2011.2014.actual)\n\nyear.2014 = 2000:2014\n\nplot(x = year.2014, y = coal.2000.2014, ylim = c(80,180), pch=16, col = \"dark orange\",\n     ylab = \"Coal Production (Quadrillion BTUs)\", xlab = \"Year\",\n     xlim = c(2000,2014), main = \"World Coal Production\")\nabline (a = lm.fit$coefficients[1], b = lm.fit$coefficients[2],\n        col = \"light pink\", lty = 2, lwd = 2)\npoints(x = 2011:2014, y = coal.2011.2014.extrapolated, pch = 16, col = \"maroon\")\nlegend(\"topleft\", c(\"Actual\", \"Extrapolation\"),\n       pch = c(16,16), lty = c(NA, NA),\n       lwd = c(NA, NA),\n       col = c(\"dark orange\", \"maroon\"))\n\n\n\nRegression Model Approach With Surrogate Data R Script\nThis part produces a time series of global coal production data from 1980-2021. The dataset we were orginally given contained data only out to 2014. This is where I used the surrogate data method to fill the data gap and then estimate emissions.\n\n#we are going to use GDP as surrogate data to predict coal production)\n\n# Q13 on hw (Trend extrapolation w/ surrogate data (GDP))\nCoalproduction <- read.csv(\"WorldCoalProduction.csv\", header = TRUE)\n\ncor(x=Coalproduction$coal[1:35], y=Coalproduction$GDP[1:35])\nlm.fit <- lm(Coalproduction$coal~Coalproduction$GDP) #we are saying that coal production is a function of GDP (because of the tilda (~))\nsummary(lm.fit)\n\n# let's take the model from summary(lm.fit) and we are going to create a data frame that inclues coal production and the coal production predictor\ncoal.production.predicted <- lm.fit$coefficients[1] +\n                                lm.fit$coefficients[2]*(Coalproduction$GDP)\nCoalproduction <- cbind.data.frame(Coalproduction, coal.production.predicted)\n\nplot(x = Coalproduction$year, y = Coalproduction$coal,\n     type=\"l\", lwd = 4, col = \"light green\", \n     ylab = \"Coal Production (Quadrillion BTUs)\", xlab = \"Year\",\n     xlim = c(1980, 2021),\n     ylim = c(65,190),\n     main = \"World Coal Production\")\npoints (x = Coalproduction$year,\n        y = Coalproduction$coal.production.predicted,\n        pch = 16, col = \"red\")\nlegend (\"topleft\", c(\"Actual Estimates\", \"Model Estimates\"),\n        pch = c(NA, 16), lwd = c(4,NA),\n        col= c(\"light green\", \"red\"))"
  },
  {
    "objectID": "Electricity_emissions.html",
    "href": "Electricity_emissions.html",
    "title": "GA Electricity Emissions",
    "section": "",
    "text": "This project includes R Script that estimated emissions from electricity usage in the state of Georgia from 1960 - 2015, calculated every ten years. This is a tier 2 analysis because we use local data and baseline emission factors from the 2006 IPCC guidelines. This is a Monte Carlo model that runs the data through multiple iterations to get the most accurate results.\n\nModel Implementation R Script\n\nResults.electricity<-ElectricityGenerationEmissions(input.filename=\"GAelectricity.csv\", fuel.types=6, nyears=7, iseed=430983, nreps = 10000)\nyears<- c(1960,1970,1980,1990,2000,2010,2015)\n\n\n\nElectricity Emissions R Script\n\n\"ElectricityGenerationEmissions\"<-\n  function(input.filename=\"NAME\", fuel.types=6,iseed=430983, nyears=7, nreps=10000)\n    # Script developed by Natalie Wiley\n    # Originally Developed: February 18th, 2022\n    # Last Update: February 18th, 2022\n    # Script estimates CO2, CH4, and N2O emissions from electricity generation from stationary sources using Tier 1 methods from the 2006 IPCC guidelines\n    # Returns MMT CO2 equivalents for each scenario\n    #\n    ###### Arguments\n    # input.filename    Name of file with activity data, which is comma delimited file with the input activity data in columns along with a header row as follows: fuel type, CO2 emission factor, min. CO2 emission factor, max. CO2 emission factor, CH4 emission factor, min. CH4 emission factor, max. CH4 emission factor, N2O emission factor, min. N2O emission factor, max. N2O emission factor, fuel amount for year 1 (in TJ), standard deviation for fuel amount,...for all years.\n    # fuel.types        Number of fuel types in the input file\n    # nyears            Number of years of data\n    # iseed             Initial seed value for random draws\n    # nreps             Number of Monte Carlo iterations\n    ##\n    ###### Begin Script\n  {\n    ###### Set Seed\n    set.seed(iseed)\n    #\n    ###### Load library\n    library(triangle)\n    ###### Import files\n    input.data<-read.csv(file=input.filename, header=TRUE, sep=\",\", fill=FALSE)\n    # ensure all input data on fuel amounts and EFs are numeric (problem with excel)\n\n    \n      for(n in (1:(9+(nyears*2)))){\n        input.data[,n+1]<-as.numeric(input.data[,n+1])\n      }\n    #\n    ###Check Validity of Input Data\n    check.fuel.type<-length(input.data[,1])==fuel.types\n    if(!check.fuel.type) {stop(\"Warning the number of fuel types in the function call\n                               does not equal the number in the input file.\")}\n    # Emissions Factors\n    for(efact in (1:fuel.types)){\n      check.CO2.EF<-input.data[efact,2]>=0\n      if(!check.CO2.EF) {stop(\"Error: Co2 EF must be greater than or equal to 0\n                             - check input file.\")\n      }\n      check.CO2.EF.min<-input.data[efact,3]<=input.data[efact,2]&input.data[efact,3]>=0\n      if(!check.CO2.EF.min) {stop(\"Error: Minimum CO2 EF must be greater than or equal to 0\n                                 and less than the EF value - Check input file.\")\n      }\n      Check.CO2.EF.max<-input.data[efact,4]>=input.data[efact,2]\n      if(!Check.CO2.EF.max) {stop(\"Error: Maximum CO2 EF must be greater than or\n                                  equal to EF value - check input file.\")\n      }\n      \n      check.CH4.EF<-input.data[efact,5]>=0\n      if(!check.CH4.EF) {stop(\"Error: CH4 EF must be greater than or equal to 0\n                             - check input file.\")\n      }\n      check.CH4.EF.min<-input.data[efact,6]<=input.data[efact,5]&input.data[efact,6]>=0\n      if(!check.CH4.EF.min) {stop(\"Error: Minimum CH4 EF must be greater than or equal to 0\n                                 and less than the EF value - Check input file.\")\n      }\n      Check.CH4.EF.max<-input.data[efact,7]>=input.data[efact,5]\n      if(!Check.CH4.EF.max) {stop(\"Error: Maximum CH4 EF must be greater than or\n                                  equal to EF value - check input file.\")\n      }\n      \n      check.N2O.EF<-input.data[efact,8]>=0\n      if(!check.N2O.EF) {stop(\"Error: N2O EF must be greater than or equal to 0\n                             - check input file.\")\n      }\n      check.N2O.EF.min<-input.data[efact,9]<=input.data[efact,8]&input.data[efact,6]>=0\n      if(!check.N2O.EF.min) {stop(\"Error: Minimum N2O EF must be greater than or equal to 0\n                                 and less than the EF value - Check input file.\")\n      }\n      Check.N2O.EF.max<-input.data[efact,10]>=input.data[efact,8]\n      if(!Check.N2O.EF.max) {stop(\"Error: Maximum N2O EF must be greater than or\n                                  equal to EF value - check input file.\")\n      }\n      \n    }\n    #\n    # Check Fuel Amounts\n    for(y in (1:nyears)){\n      for (f in (1:fuel.types)){\n        check.fuel.amount<-input.data[f,11+((y-1)*2)]>=0\n        if(!check.fuel.amount) {stop(\"Error: Fuel amounts must be greater than or equal to 0\n                                     - Check input file.\")\n        }\n        check.fuel.sd<-input.data[f,12+((y-1)*2)]>=0\n        if(!check.fuel.sd) {stop(\"Error: Fuel Standard Deciations must be greater than or equal to 0\n                                 - Check input file.\")\n        }\n      }\n    }\n    #\n    #### Simulate nreps of EF and Fuel Amounts\n    ## Emission Factors\n    # CO2\n    CO2.EF.sim<-matrix(0,nrow=fuel.types,ncol = nreps)\n    for( f in (1:fuel.types)) {\n      CO2.EF.sim[f,]<-rtriangle(nreps, a=input.data[f,3],b=input.data[f,4],\n                                c=input.data[f,2])\n    }\n    # CH4\n    CH4.EF.sim<-matrix(0,nrow=fuel.types,ncol = nreps)\n    for( f in (1:fuel.types)) {\n      CH4.EF.sim[f,]<-rtriangle(nreps, a=input.data[f,6],b=input.data[f,7],\n                                c=input.data[f,5])\n    }\n    # N2O\n    N2O.EF.sim<-matrix(0,nrow=fuel.types,ncol = nreps)\n    for( f in (1:fuel.types)) {\n      N2O.EF.sim[f,]<-rtriangle(nreps, a=input.data[f,9],b=input.data[f,10],\n                                c=input.data[f,8])\n    }\n    ### Fuel Amount\n    fuel.amount.sim<-matrix(0,nrow=fuel.types*nyears,ncol=nreps)\n    for(y in (1:nyears)){\n      for(f in (1:fuel.types)){\n        fuel.amount.sim[f+(fuel.types*(y-1)),]<-rnorm(nreps,mean=input.data[f,11+((y-1)*2)],\n                                                      sd=input.data[f,12+((y-1)*2)])\n      }\n    }\n   ###### Calculate emissions\n    # IPCC 2006 GL: Emissions = Fuel Consumption * EF\n    # Units: Emissions in kg, Fuel.amount in TJ and EF is kg/TJ\n    ### Deterministic Estimation\n    Deterministic.CO2eq<-matrix(0, nrow=fuel.types, ncol=nyears)\n    for (y in (1:nyears)){\n      for (d in (1:fuel.types)){\n        Deterministic.CO2eq[d,y]<-(input.data[d,2]*input.data[d,11+((y-1)*2)])+\n                                  (input.data[d,5]*input.data[d,11 +((y-1)*2)])*25 +\n          (input.data[d,8]*input.data[d,11 +((y-1)*2)])*298\n      }\n    }\n    # Sum the individual fuel sources to obtain total CO2eq emissions\n      Deterministic.CO2eq.total<-apply(Deterministic.CO2eq, MAR=2, FUN=\"sum\")\n      #\n      ### Probabilistic Estimation\n      Probabilistic.CO2eq<-matrix(0, nrow=fuel.types*nyears, ncol=nreps)\n      for (y in (1:nyears)){\n        for (p in (1:fuel.types)){\n          Probabilistic.CO2eq[p+(fuel.types*(y-1)),]<-\n            ((CO2.EF.sim[p,]*fuel.amount.sim[p+(fuel.types*(y-1)),]))+\n            ((CH4.EF.sim[p,]*fuel.amount.sim[p+(fuel.types*(y-1)),])*25)+\n            ((N2O.EF.sim[p,]*fuel.amount.sim[p+(fuel.types*(y-1)),])*298)\n        }\n      }\n    \n    # Sum the individual fuel sources to obtain total CO2eq emissions\n      Probabilistic.CO2eq.total<-matrix(0, nrow=nyears, ncol=nreps)\n      for (y in (1:nyears)){\n        Probabilistic.CO2eq.total[y,]<-apply (Probabilistic.CO2eq[(1+((y-1)*fuel.types)): \n                                                                    (fuel.types+ ((y-1)*fuel.types)),],MAR=2, FUN=\"sum\")\n      }\n      \n      #\n      ###### Estimate median and confidence intervals, check emissions\n      \n      #\n      # Create matrix with col 1 = mean, col 2 = 2.5 percentile, and col 3 = 97.5 percentile\n      emission.results<-matrix(0, nrow=nyears, ncol=3)\n      for (y in (1:nyears)){\n        emission.results[y,1]<- median(Probabilistic.CO2eq.total[y,])\n        q<-quantile(Probabilistic.CO2eq.total[y,], probs = c(0.025, 0.975))\n        emission.results[y,2]<- q[1]\n        emission.results[y,3]<- q[2]\n        check.emissions<- Deterministic.CO2eq.total[y]>=emission.results[y,2]&\n          Deterministic.CO2eq.total[y]<=emission.results[y,3]\n        if(!check.emissions){ \n          cat(\"WARNING: Deterministic Solution for year\", y, \"is outside of its respective condifence interval.\")\n          }\n      }\n      \n      ###### Return Statement\n      # Convert emissions to MMT CO2 from kg CO2\n      emission.results<-emission.results/10^9\n      colnames(emission.results)<-c(\"median.MMTCO2\", \"2.5 Percentile\", \"97.5 Percentile\")\n      return(emission.results)\n      #\n      ###### End Script\n  }"
  },
  {
    "objectID": "Emission_Factors.html",
    "href": "Emission_Factors.html",
    "title": "Custom Soil Emission Factors",
    "section": "",
    "text": "Creating custom emission factors to assess soil carbon stock using multiple management practices. These custom emission factors were ran using linear mixed effect modeling practices shown in the R Script below.\n\n#Estimating Emission Factors using a linear mixed effect model (LME)\n\n  #LME model using backwards stepwise method\n\n  #Using mixed effect model because we have fixed and random variables\n\n#----load nlme package (linear and non linear mixed effects model)-----\n\nlibrary(nlme)\n\n#----Read in EF input file----\n\nLU.data<-read.csv(\"data/SoilCCult.csv\", header=TRUE)\n\nmanagement.data<-read.csv(\"data/SoilCManagement.csv\", header=TRUE)\n\nCinput.data<-read.csv(\"data/SoilCInput.csv\", header=TRUE)\n\n#-----Test for correlation in predictor variables-------\n\ncor(LU.data[,c(\"years\", \"years2\", \"dep1\", \"dep2\")])\n\n             years      years2       dep1         dep2\nyears  1.000000000  0.94730657 0.02220118  0.001486767\nyears2 0.947306573  1.00000000 0.01113563 -0.013561348\ndep1   0.022201178  0.01113563 1.00000000  0.928455277\ndep2   0.001486767 -0.01356135 0.92845528  1.000000000\n\ncor(management.data[,c(\"years\", \"years2\", \"dep1\", \"dep2\")])\n\n           years    years2      dep1      dep2\nyears  1.0000000 0.9641991 0.2098040 0.2105650\nyears2 0.9641991 1.0000000 0.2086141 0.2123727\ndep1   0.2098040 0.2086141 1.0000000 0.9513001\ndep2   0.2105650 0.2123727 0.9513001 1.0000000\n\ncor(Cinput.data[,c(\"years\", \"years2\", \"dep1\", \"dep2\")])\n\n           years    years2      dep1      dep2\nyears  1.0000000 0.9778155 0.1705907 0.1374545\nyears2 0.9778155 1.0000000 0.1705167 0.1358530\ndep1   0.1705907 0.1705167 1.0000000 0.9557745\ndep2   0.1374545 0.1358530 0.9557745 1.0000000\n\n#----Data check via Visualization----\n\n###Aquic\n\nbarplot(table(Cinput.data$aquic),ylab = \"Times appeared in Data\", main= \"aquic\")\n\n\n\nbarplot(table(management.data$aquic),ylab = \"Times appeared in Data\", main= \"aquic\")\n\n\n\nbarplot(table(LU.data$aquic),ylab = \"Times appeared in Data\", main= \"aquic\")\n\n\n\n###Years and Years2 (years squared)\n\nbarplot(table(Cinput.data$years),ylab = \"Times appeared in Data\", main= \"years\")\n\n\n\nbarplot(table(management.data$years),ylab = \"Times appeared in Data\", main= \"years\")\n\n\n\nbarplot(table(LU.data$years),ylab = \"Times appeared in Data\", main= \"years\")\n\n\n\n###Top and bottom\n\nbarplot(table(Cinput.data$top),ylab = \"Times appeared in Data\", main= \"top\")\n\n\n\nbarplot(table(management.data$top),ylab = \"Times appeared in Data\", main= \"top\")\n\n\n\nbarplot(table(LU.data$top),ylab = \"Times appeared in Data\", main= \"top\")\n\n\n\nbarplot(table(Cinput.data$bottom),ylab = \"Times appeared in Data\", main= \"bottom\")\n\n\n\nbarplot(table(management.data$bottom),ylab = \"Times appeared in Data\", main= \"bottom\")\n\n\n\nbarplot(table(LU.data$bottom),ylab = \"Times appeared in Data\", main= \"bottom\")\n\n\n\n###Temp\n\nbarplot(table(Cinput.data$ipcc.temp),ylab = \"Times appeared in Data\", main= \"Temp\")\n\n\n\nbarplot(table(management.data$ipcc.temp),ylab = \"Times appeared in Data\", main= \"Temp\")\n\n\n\nbarplot(table(LU.data$ipcc.temp),ylab = \"Times appeared in Data\", main= \"Temp\")\n\n\n\n###Precipitation\n\nbarplot(table(Cinput.data$ipcc.pre),ylab = \"Times appeared in Data\", main= \"Precipitation Climate\")\n\n\n\nbarplot(table(management.data$ipcc.pre),ylab = \"Times appeared in Data\", main= \"Precipitation Climate\")\n\n\n\nbarplot(table(LU.data$ipcc.pre),ylab = \"Times appeared in Data\", main= \"Precipitation Climate\")\n\n\n\n###Soil type\n\nbarplot(table(Cinput.data$ipcc.soil),ylab = \"Times appeared in Data\", main= \"Soil Type\")\n\n\n\nbarplot(table(management.data$ipcc.soil),ylab = \"Times appeared in Data\", main= \"Soil Type\")\n\n\n\nbarplot(table(LU.data$ipcc.soil),ylab = \"Times appeared in Data\", main= \"Soil Type\")\n\n\n\n#_____________________________________________________________________________________________________\n\n  #MANAGEMENT MODEL DEVELOPMENT\n\n#-------Test full model with all variables as main effects-------\n\ntest.fit<-lme(ch.cstock~ch.till+years+years2+dep1+dep2+aquic+ipcc.soil+ipcc.pre+ipcc.temp,\n\n              random = ~1|ran.exp/ran.yrexp, data = management.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: management.data \n        AIC       BIC   logLik\n  -74.82665 -11.80577 54.41332\n\nRandom effects:\n Formula: ~1 | ran.exp\n         (Intercept)\nStdDev: 2.888098e-05\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n        (Intercept)  Residual\nStdDev: 2.98371e-05 0.2019543\n\nFixed effects:  ch.cstock ~ ch.till + years + years2 + dep1 + dep2 + aquic +      ipcc.soil + ipcc.pre + ipcc.temp \n                      Value  Std.Error  DF   t-value p-value\n(Intercept)       1.2052050 0.12792012 197  9.421544  0.0000\nch.tillrt        -0.0424258 0.02644707 197 -1.604176  0.1103\nyears             0.0034526 0.00673113  30  0.512933  0.6118\nyears2           -0.0000308 0.00018991  30 -0.162072  0.8723\ndep1             -0.0214199 0.00223077 197 -9.602025  0.0000\ndep2              0.0002240 0.00002812 197  7.966228  0.0000\naquic            -0.0038566 0.04172614  60 -0.092427  0.9267\nipcc.soilham      0.0294098 0.10978879  60  0.267876  0.7897\nipcc.soillam     -0.0166472 0.11363556  60 -0.146497  0.8840\nipcc.soilsan     -0.0365804 0.23503276  60 -0.155639  0.8768\nipcc.soilspo     -0.0318737 0.23362227  60 -0.136433  0.8919\nipcc.soilwetland  0.0219131 0.11953004  60  0.183327  0.8552\nipcc.prewet       0.0890616 0.03076183  60  2.895199  0.0053\nipcc.tempwarm     0.0017827 0.03373953  60  0.052837  0.9580\n Correlation: \n                 (Intr) ch.tll years  years2 dep1   dep2   aquic  ipcc.slh\nch.tillrt         0.043                                                   \nyears            -0.387 -0.006                                            \nyears2            0.356 -0.019 -0.965                                     \ndep1             -0.185 -0.099 -0.020  0.032                              \ndep2              0.140  0.085  0.039 -0.063 -0.952                       \naquic             0.087 -0.053 -0.114  0.145  0.043 -0.071                \nipcc.soilham     -0.910 -0.104  0.077 -0.073  0.048 -0.021 -0.078         \nipcc.soillam     -0.877 -0.058  0.251 -0.217  0.099 -0.051 -0.052  0.900  \nipcc.soilsan     -0.440 -0.012  0.111 -0.096 -0.018  0.022 -0.004  0.455  \nipcc.soilspo     -0.413 -0.011  0.034 -0.025 -0.017  0.021  0.004  0.452  \nipcc.soilwetland -0.831 -0.071  0.163 -0.171  0.022  0.008 -0.369  0.895  \nipcc.prewet      -0.242  0.043 -0.022  0.001 -0.208  0.191 -0.265  0.162  \nipcc.tempwarm    -0.144 -0.048 -0.362  0.317  0.082 -0.102  0.067  0.191  \n                 ipcc.sll ipcc.slsn ipcc.slsp ipcc.slw ipcc.p\nch.tillrt                                                    \nyears                                                        \nyears2                                                       \ndep1                                                         \ndep2                                                         \naquic                                                        \nipcc.soilham                                                 \nipcc.soillam                                                 \nipcc.soilsan      0.433                                      \nipcc.soilspo      0.416    0.218                             \nipcc.soilwetland  0.851    0.410     0.400                   \nipcc.prewet      -0.020    0.035     0.038     0.143         \nipcc.tempwarm    -0.102    0.073     0.102     0.032    0.264\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.47201240 -0.58924334 -0.09323985  0.43132818  4.08358277 \n\nNumber of Observations: 301\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    69                    101 \n\n#--------Diagnostic Plots, Residual Plot--------- #do residual plot after test.fit model for all variables\n\nresid<-residuals(test.fit)\n\nplot(fitted(test.fit), resid)\n\nabline(0,0)\n\n\n\n### QQ normal plot\n\nqqnorm(resid)\n\nqqline(resid)\n\n\n\n#-----Remove variables w/ high p-values to see if it improves the model------\n\n###Using backwards stepwise method\n\n###If AIC goes UP by 2, it means the variable I took away was important. If it goes down by 2, the variable was not important\n\n#___removed years2 because high p value___\n\ntest.fit<-lme(ch.cstock~ch.till+years+dep1+dep2+aquic+ipcc.soil+ipcc.pre+ipcc.temp,\n\n              random = ~1|ran.exp/ran.yrexp, data = management.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: management.data \n       AIC       BIC   logLik\n  -76.7991 -17.48534 54.39955\n\nRandom effects:\n Formula: ~1 | ran.exp\n         (Intercept)\nStdDev: 1.303409e-05\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept)  Residual\nStdDev: 3.257696e-05 0.2019636\n\nFixed effects:  ch.cstock ~ ch.till + years + dep1 + dep2 + aquic + ipcc.soil +      ipcc.pre + ipcc.temp \n                      Value  Std.Error  DF   t-value p-value\n(Intercept)       1.2125926 0.11932090 197 10.162449  0.0000\nch.tillrt        -0.0425056 0.02639774 197 -1.610199  0.1090\nyears             0.0024001 0.00176686  31  1.358386  0.1841\ndep1             -0.0214085 0.00222589 197 -9.617962  0.0000\ndep2              0.0002237 0.00002802 197  7.985297  0.0000\naquic            -0.0028738 0.04121330  60 -0.069731  0.9446\nipcc.soilham      0.0281122 0.10931122  60  0.257176  0.7979\nipcc.soillam     -0.0206449 0.11073860  60 -0.186429  0.8527\nipcc.soilsan     -0.0402531 0.23354192  60 -0.172359  0.8637\nipcc.soilspo     -0.0328137 0.23315511  60 -0.140738  0.8885\nipcc.soilwetland  0.0185992 0.11756895  60  0.158198  0.8748\nipcc.prewet       0.0890658 0.03070977  60  2.900245  0.0052\nipcc.tempwarm     0.0035184 0.03194056  60  0.110155  0.9127\n Correlation: \n                 (Intr) ch.tll years  dep1   dep2   aquic  ipcc.slh ipcc.sll\nch.tillrt         0.053                                                     \nyears            -0.174 -0.092                                              \ndep1             -0.210 -0.099  0.040                                       \ndep2              0.175  0.084 -0.083 -0.953                                \naquic             0.038 -0.051  0.103  0.039 -0.063                         \nipcc.soilham     -0.948 -0.106  0.024  0.051 -0.025 -0.069                  \nipcc.soillam     -0.877 -0.063  0.162  0.108 -0.066 -0.021  0.908           \nipcc.soilsan     -0.437 -0.014  0.070 -0.015  0.017  0.010  0.452    0.425  \nipcc.soilspo     -0.432 -0.011  0.040 -0.017  0.019  0.007  0.452    0.420  \nipcc.soilwetland -0.837 -0.075 -0.009  0.028 -0.003 -0.353  0.898    0.846  \nipcc.prewet      -0.259  0.043 -0.081 -0.208  0.192 -0.268  0.163   -0.021  \nipcc.tempwarm    -0.290 -0.044 -0.224  0.076 -0.087  0.023  0.226   -0.036  \n                 ipcc.slsn ipcc.slsp ipcc.slw ipcc.p\nch.tillrt                                           \nyears                                               \ndep1                                                \ndep2                                                \naquic                                               \nipcc.soilham                                        \nipcc.soillam                                        \nipcc.soilsan                                        \nipcc.soilspo      0.217                             \nipcc.soilwetland  0.401     0.402                   \nipcc.prewet       0.035     0.038     0.146         \nipcc.tempwarm     0.109     0.116     0.092    0.279\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.47927789 -0.59652632 -0.09190044  0.44295403  4.09368399 \n\nNumber of Observations: 301\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    69                    101 \n\n### AIC went from -74 to -76, is that considered up or down in this case? I think down… so we keep years2?\n\n###leaving out years2 because we want the model as simple as possible\n\n#___removed ipcc.temp because high p value___\n\ntest.fit<-lme(ch.cstock~ch.till+years+dep1+dep2+aquic+ipcc.soil+ipcc.pre,\n\n              random = ~1|ran.exp/ran.yrexp, data = management.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: management.data \n        AIC       BIC   logLik\n  -78.78642 -23.17977 54.39321\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev: 8.53128e-06\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept)  Residual\nStdDev: 3.132939e-05 0.2019678\n\nFixed effects:  ch.cstock ~ ch.till + years + dep1 + dep2 + aquic + ipcc.soil +      ipcc.pre \n                      Value  Std.Error  DF   t-value p-value\n(Intercept)       1.2164087 0.11398593 197 10.671568  0.0000\nch.tillrt        -0.0423765 0.02632657 197 -1.609646  0.1091\nyears             0.0024438 0.00171885  31  1.421734  0.1651\ndep1             -0.0214271 0.00221567 197 -9.670715  0.0000\ndep2              0.0002240 0.00002786 197  8.039169  0.0000\naquic            -0.0029769 0.04113220  61 -0.072374  0.9425\nipcc.soilham      0.0253883 0.10629540  61  0.238846  0.8120\nipcc.soillam     -0.0202092 0.11047865  61 -0.182924  0.8555\nipcc.soilsan     -0.0430658 0.23174483  61 -0.185833  0.8532\nipcc.soilspo     -0.0358010 0.23117643  61 -0.154864  0.8774\nipcc.soilwetland  0.0174046 0.11686750  61  0.148926  0.8821\nipcc.prewet       0.0881233 0.02944326  61  2.992989  0.0040\n Correlation: \n                 (Intr) ch.tll years  dep1   dep2   aquic  ipcc.slh ipcc.sll\nch.tillrt         0.042                                                     \nyears            -0.257 -0.105                                              \ndep1             -0.197 -0.096  0.059                                       \ndep2              0.157  0.080 -0.106 -0.952                                \naquic             0.047 -0.050  0.111  0.038 -0.061                         \nipcc.soilham     -0.947 -0.098  0.078  0.034 -0.006 -0.076                  \nipcc.soillam     -0.928 -0.065  0.158  0.111 -0.070 -0.020  0.941           \nipcc.soilsan     -0.426 -0.009  0.097 -0.024  0.026  0.008  0.441    0.431  \nipcc.soilspo     -0.419 -0.006  0.068 -0.026  0.030  0.005  0.440    0.428  \nipcc.soilwetland -0.850 -0.072  0.012  0.021  0.005 -0.357  0.904    0.853  \nipcc.prewet      -0.194  0.058 -0.020 -0.240  0.226 -0.286  0.107   -0.011  \n                 ipcc.slsn ipcc.slsp ipcc.slw\nch.tillrt                                    \nyears                                        \ndep1                                         \ndep2                                         \naquic                                        \nipcc.soilham                                 \nipcc.soillam                                 \nipcc.soilsan                                 \nipcc.soilspo      0.207                      \nipcc.soilwetland  0.395     0.396            \nipcc.prewet       0.005     0.006     0.125  \n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.47834042 -0.58885735 -0.09702779  0.43461959  4.09048124 \n\nNumber of Observations: 301\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    69                    101 \n\n###changed AIC from -76 to -78, leaving out ipcc.temp\n\n#____Removed aquic_____\n\ntest.fit<-lme(ch.cstock~ch.till+years+dep1+dep2+ipcc.soil+ipcc.pre,\n\n              random = ~1|ran.exp/ran.yrexp, data = management.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: management.data \n       AIC      BIC  logLik\n  -81.9712 -29.7498 54.9856\n\nRandom effects:\n Formula: ~1 | ran.exp\n         (Intercept)\nStdDev: 2.371439e-05\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n        (Intercept)  Residual\nStdDev:  0.02037141 0.2014043\n\nFixed effects:  ch.cstock ~ ch.till + years + dep1 + dep2 + ipcc.soil + ipcc.pre \n                      Value  Std.Error  DF   t-value p-value\n(Intercept)       1.3593818 0.08082279 203 16.819288  0.0000\nch.tillrt        -0.0433030 0.02635614 203 -1.642995  0.1019\nyears             0.0025717 0.00173446  31  1.482695  0.1483\ndep1             -0.0211571 0.00217531 203 -9.726012  0.0000\ndep2              0.0002207 0.00002743 203  8.044679  0.0000\nipcc.soilham     -0.1216511 0.06834101  63 -1.780060  0.0799\nipcc.soillam     -0.1647784 0.07512726  63 -2.193323  0.0320\nipcc.soilsan     -0.1894279 0.21724309  63 -0.871963  0.3865\nipcc.soilspo     -0.1826748 0.21655800  63 -0.843537  0.4021\nipcc.soilwetland -0.1319488 0.07341949  63 -1.797190  0.0771\nipcc.prewet       0.0868789 0.02875310  63  3.021548  0.0036\n Correlation: \n                 (Intr) ch.tll years  dep1   dep2   ipcc.slh ipcc.sll ipcc.slsn\nch.tillrt         0.060                                                        \nyears            -0.402 -0.100                                                 \ndep1             -0.303 -0.089  0.053                                          \ndep2              0.266  0.073 -0.097 -0.952                                   \nipcc.soilham     -0.891 -0.157  0.166  0.091 -0.070                            \nipcc.soillam     -0.849 -0.098  0.267  0.189 -0.149  0.869                     \nipcc.soilsan     -0.272 -0.010  0.115 -0.015  0.011  0.291    0.276            \nipcc.soilspo     -0.260 -0.007  0.083 -0.017  0.015  0.286    0.269    0.096   \nipcc.soilwetland -0.773 -0.143  0.112  0.083 -0.075  0.862    0.790    0.266   \nipcc.prewet      -0.276  0.047  0.013 -0.224  0.205  0.141   -0.026    0.006   \n                 ipcc.slsp ipcc.slw\nch.tillrt                          \nyears                              \ndep1                               \ndep2                               \nipcc.soilham                       \nipcc.soillam                       \nipcc.soilsan                       \nipcc.soilspo                       \nipcc.soilwetland  0.263            \nipcc.prewet       0.006     0.036  \n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.71258136 -0.57976248 -0.08043712  0.43920736  4.07347191 \n\nNumber of Observations: 308\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    70                    102 \n\n###Leaving out aquic because AIC changed from -78 to -81\n\n#____removing ipcc.soil____\n\ntest.fit<-lme(ch.cstock~ch.till+years+dep1+dep2+ipcc.pre,\n\n              random = ~1|ran.exp/ran.yrexp, data = management.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: management.data \n        AIC       BIC   logLik\n  -87.44697 -53.87607 52.72348\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.01274511\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n        (Intercept)  Residual\nStdDev:  0.04766797 0.1984883\n\nFixed effects:  ch.cstock ~ ch.till + years + dep1 + dep2 + ipcc.pre \n                 Value  Std.Error  DF  t-value p-value\n(Intercept)  1.2155265 0.03673901 203 33.08544  0.0000\nch.tillrt   -0.0483838 0.02622587 203 -1.84489  0.0665\nyears        0.0037403 0.00174900  31  2.13852  0.0405\ndep1        -0.0206351 0.00210659 203 -9.79550  0.0000\ndep2         0.0002162 0.00002675 203  8.08192  0.0000\nipcc.prewet  0.0830077 0.02911534  68  2.85100  0.0058\n Correlation: \n            (Intr) ch.tll years  dep1   dep2  \nch.tillrt   -0.159                            \nyears       -0.545 -0.101                     \ndep1        -0.432 -0.077 -0.017              \ndep2         0.399  0.064 -0.045 -0.950       \nipcc.prewet -0.522  0.098  0.073 -0.165  0.154\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.4822612 -0.5733692 -0.0913330  0.4402047  3.9800368 \n\nNumber of Observations: 308\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    70                    102 \n\n###Leaving out ipcc.soil  because AIC changed from -81 to -87\n\n#____removing ipcc.pre____*KEPT IPCC.PRE\n\ntest.fit<-lme(ch.cstock~ch.till+years+dep1+dep2,\n\n              random = ~1|ran.exp/ran.yrexp, data = management.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: management.data \n        AIC       BIC   logLik\n  -81.89104 -52.05024 48.94552\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.04089841\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n        (Intercept)  Residual\nStdDev:   0.0410433 0.1994555\n\nFixed effects:  ch.cstock ~ ch.till + years + dep1 + dep2 \n                 Value  Std.Error  DF  t-value p-value\n(Intercept)  1.2772696 0.03284326 203 38.88985  0.0000\nch.tillrt   -0.0567931 0.02661311 203 -2.13403  0.0340\nyears        0.0031722 0.00182699  31  1.73630  0.0924\ndep1        -0.0200671 0.00210794 203 -9.51980  0.0000\ndep2         0.0002095 0.00002674 203  7.83402  0.0000\n Correlation: \n          (Intr) ch.tll years  dep1  \nch.tillrt -0.138                     \nyears     -0.602 -0.088              \ndep1      -0.611 -0.059  0.011       \ndep2       0.564  0.049 -0.071 -0.949\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.3393973 -0.5998968 -0.1325983  0.4353780  3.9937867 \n\nNumber of Observations: 308\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    70                    102 \n\n### Keeping ipcc.pre because AIC changed from -87 back to -81\n\n#----Best Fit Management Model-----\n\ntest.fit.management<-lme(ch.cstock~ch.till+years+dep1+dep2+ipcc.pre,\n\n              random = ~1|ran.exp/ran.yrexp, data = management.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit.management)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: management.data \n        AIC       BIC   logLik\n  -87.44697 -53.87607 52.72348\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.01274511\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n        (Intercept)  Residual\nStdDev:  0.04766797 0.1984883\n\nFixed effects:  ch.cstock ~ ch.till + years + dep1 + dep2 + ipcc.pre \n                 Value  Std.Error  DF  t-value p-value\n(Intercept)  1.2155265 0.03673901 203 33.08544  0.0000\nch.tillrt   -0.0483838 0.02622587 203 -1.84489  0.0665\nyears        0.0037403 0.00174900  31  2.13852  0.0405\ndep1        -0.0206351 0.00210659 203 -9.79550  0.0000\ndep2         0.0002162 0.00002675 203  8.08192  0.0000\nipcc.prewet  0.0830077 0.02911534  68  2.85100  0.0058\n Correlation: \n            (Intr) ch.tll years  dep1   dep2  \nch.tillrt   -0.159                            \nyears       -0.545 -0.101                     \ndep1        -0.432 -0.077 -0.017              \ndep2         0.399  0.064 -0.045 -0.950       \nipcc.prewet -0.522  0.098  0.073 -0.165  0.154\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.4822612 -0.5733692 -0.0913330  0.4402047  3.9800368 \n\nNumber of Observations: 308\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    70                    102 \n\n#____________________________________________________________________________________________________________\n\n  #cINPUT MODEL DEVELOPMENT\n\n#-------Test full model with all variables as main effects-------\n\n###Did not include soil type because it does not matter for Cinput data\n\ntest.fit<-lme(ch.cstock~ch.inp+years+years2+dep1+dep2+aquic+ipcc.pre+ipcc.temp,\n\n              random = ~1|ran.exp/ran.yrexp, data = Cinput.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: Cinput.data \n        AIC       BIC   logLik\n  -218.2465 -186.1726 121.1233\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.02133355\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept)   Residual\nStdDev: 1.165634e-06 0.07551378\n\nFixed effects:  ch.cstock ~ ch.inp + years + years2 + dep1 + dep2 + aquic + ipcc.pre +      ipcc.temp \n                   Value  Std.Error DF   t-value p-value\n(Intercept)    1.0613041 0.04821888 58 22.010133  0.0000\nch.inpl       -0.1273723 0.02700289 58 -4.716987  0.0000\nyears         -0.0031645 0.00403780 22 -0.783723  0.4416\nyears2         0.0000647 0.00009054 22  0.714163  0.4826\ndep1           0.0031662 0.00151394 58  2.091352  0.0409\ndep2          -0.0000222 0.00001901 58 -1.170089  0.2468\naquic         -0.0509499 0.08979628 18 -0.567394  0.5775\nipcc.prewet    0.0206511 0.02953017 18  0.699321  0.4933\nipcc.tempwarm -0.0239228 0.02288024 18 -1.045567  0.3096\n Correlation: \n              (Intr) ch.npl years  years2 dep1   dep2   aquic  ipcc.p\nch.inpl       -0.652                                                 \nyears         -0.780  0.272                                          \nyears2         0.731 -0.289 -0.974                                   \ndep1          -0.270  0.044 -0.016 -0.019                            \ndep2           0.244 -0.033  0.012  0.013 -0.957                     \naquic          0.128  0.103 -0.233  0.186  0.070 -0.049              \nipcc.prewet   -0.509  0.503  0.360 -0.324 -0.156  0.150 -0.166       \nipcc.tempwarm -0.170 -0.189  0.097 -0.015  0.058 -0.080 -0.182 -0.268\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.24478048 -0.54906957 -0.01933017  0.50813897  3.33744254 \n\nNumber of Observations: 107\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    22                     46 \n\n#____Removing aquic because high p value____\n\ntest.fit<-lme(ch.cstock~ch.inp+years+years2+dep1+dep2+ipcc.pre+ipcc.temp,\n\n              random = ~1|ran.exp/ran.yrexp, data = Cinput.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: Cinput.data \n        AIC       BIC   logLik\n  -219.8959 -190.4948 120.9479\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.02155949\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept)   Residual\nStdDev: 1.404757e-06 0.07559902\n\nFixed effects:  ch.cstock ~ ch.inp + years + years2 + dep1 + dep2 + ipcc.pre +      ipcc.temp \n                   Value  Std.Error DF   t-value p-value\n(Intercept)    1.0647743 0.04770339 58 22.320728  0.0000\nch.inpl       -0.1257814 0.02679209 58 -4.694723  0.0000\nyears         -0.0036977 0.00391837 22 -0.943685  0.3556\nyears2         0.0000742 0.00008879 22  0.835624  0.4124\ndep1           0.0032287 0.00150467 58  2.145753  0.0361\ndep2          -0.0000228 0.00001891 58 -1.205032  0.2331\nipcc.prewet    0.0178249 0.02907533 19  0.613060  0.5471\nipcc.tempwarm -0.0262489 0.02247104 19 -1.168122  0.2572\n Correlation: \n              (Intr) ch.npl years  years2 dep1   dep2   ipcc.p\nch.inpl       -0.674                                          \nyears         -0.777  0.306                                   \nyears2         0.725 -0.315 -0.974                            \ndep1          -0.281  0.037  0.000 -0.033                     \ndep2           0.252 -0.027  0.001  0.022 -0.957              \nipcc.prewet   -0.498  0.529  0.335 -0.302 -0.146  0.144       \nipcc.tempwarm -0.150 -0.173  0.057  0.020  0.072 -0.090 -0.308\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.24054950 -0.55163767 -0.06600909  0.52227609  3.36081396 \n\nNumber of Observations: 107\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    22                     46 \n\n###Leave out aquic\n\n#____Removing ipcc.pre_____\n\ntest.fit<-lme(ch.cstock~ch.inp+years+years2+dep1+dep2+ipcc.temp,\n\n              random = ~1|ran.exp/ran.yrexp, data = Cinput.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: Cinput.data \n        AIC       BIC   logLik\n  -221.5017 -194.7734 120.7508\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.02279106\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept)   Residual\nStdDev: 6.608399e-07 0.07549399\n\nFixed effects:  ch.cstock ~ ch.inp + years + years2 + dep1 + dep2 + ipcc.temp \n                   Value  Std.Error DF   t-value p-value\n(Intercept)    1.0787360 0.04157504 58 25.946720  0.0000\nch.inpl       -0.1341617 0.02286890 58 -5.866557  0.0000\nyears         -0.0044796 0.00371354 22 -1.206295  0.2405\nyears2         0.0000901 0.00008522 22  1.056801  0.3021\ndep1           0.0033722 0.00148184 58  2.275709  0.0266\ndep2          -0.0000246 0.00001862 58 -1.318874  0.1924\nipcc.tempwarm -0.0217812 0.02160346 20 -1.008228  0.3254\n Correlation: \n              (Intr) ch.npl years  years2 dep1   dep2  \nch.inpl       -0.558                                   \nyears         -0.748  0.162                            \nyears2         0.695 -0.193 -0.972                     \ndep1          -0.408  0.131  0.054 -0.083              \ndep2           0.372 -0.119 -0.051  0.069 -0.956       \nipcc.tempwarm -0.370 -0.010  0.175 -0.077  0.028 -0.047\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.21678502 -0.58798692 -0.06059058  0.50893876  3.21488084 \n\nNumber of Observations: 107\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    22                     46 \n\n###Leave out ipcc.pre\n\n#_____Removing ipcc.temp____\n\ntest.fit<-lme(ch.cstock~ch.inp+years+years2+dep1+dep2,\n\n              random = ~1|ran.exp/ran.yrexp, data = Cinput.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: Cinput.data \n        AIC       BIC   logLik\n  -222.4738 -198.4183 120.2369\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.02537353\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept)   Residual\nStdDev: 3.806715e-07 0.07533366\n\nFixed effects:  ch.cstock ~ ch.inp + years + years2 + dep1 + dep2 \n                 Value  Std.Error DF   t-value p-value\n(Intercept)  1.0624051 0.03926304 58 27.058654  0.0000\nch.inpl     -0.1336006 0.02330449 58 -5.732826  0.0000\nyears       -0.0038257 0.00372994 22 -1.025661  0.3162\nyears2       0.0000831 0.00008682 22  0.956987  0.3490\ndep1         0.0034261 0.00147686 58  2.319843  0.0239\ndep2        -0.0000255 0.00001852 58 -1.379507  0.1730\n Correlation: \n        (Intr) ch.npl years  years2 dep1  \nch.inpl -0.603                            \nyears   -0.750  0.167                     \nyears2   0.721 -0.195 -0.976              \ndep1    -0.418  0.120  0.052 -0.082       \ndep2     0.372 -0.109 -0.044  0.066 -0.956\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.11617924 -0.62191195 -0.03337844  0.53035651  3.11400864 \n\nNumber of Observations: 107\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    22                     46 \n\n#only brought down AIC by 1, might keep out? Means it really has no affect on the model, but we want the model as simple as possible anyway.\n\n###NOTE: Taking out years2 because it worsened the model\n\n#----Best Fit C Input Model-----\n\ntest.fit.CInput<-lme(ch.cstock~ch.inp+years+dep1+dep2,\n\n              random = ~1|ran.exp/ran.yrexp, data = Cinput.data, method = \"REML\", na.action = na.omit)\n\nsummary(test.fit.CInput)\n\nLinear mixed-effects model fit by REML\n  Data: Cinput.data \n        AIC       BIC   logLik\n  -164.3576 -143.3578 90.17879\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:    0.030629\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept)   Residual\nStdDev: 3.188172e-07 0.07654272\n\nFixed effects:  ch.cstock ~ ch.inp + years + dep1 + dep2 \n                 Value   Std.Error DF  t-value p-value\n(Intercept)  1.0342824 0.027920709 58 37.04356  0.0000\nch.inpl     -0.1280234 0.023610778 58 -5.42224  0.0000\nyears       -0.0003797 0.000856623 23 -0.44328  0.6617\ndep1         0.0035614 0.001463052 58  2.43426  0.0180\ndep2        -0.0000268 0.000018323 58 -1.46459  0.1484\n Correlation: \n        (Intr) ch.npl years  dep1  \nch.inpl -0.675                     \nyears   -0.330 -0.099              \ndep1    -0.492  0.086 -0.122       \ndep2     0.444 -0.080  0.090 -0.956\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.10382963 -0.55572607  0.02143947  0.53793687  3.08551597 \n\nNumber of Observations: 107\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    22                     46 \n\n#________________________________________________________________________________________________\n\n  #LAND USE MODEL DEVELOPMENT\n\n#-------Test full model with all variables as main effects-------\n\n###Did not include soil type pr aquic because it does not matter for Cinput data because we did not have enough soil type representation or aquic sites to fully represent the model\n\ntest.fit<-lme(ch.cstock~years+years2+dep1+dep2+ipcc.prec+ipcc.temp,\n\n              random = ~1|ran.exp/ran.yrexp, data = LU.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: LU.data \n      AIC      BIC   logLik\n  10.1963 39.75457 4.901848\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.07900865\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n        (Intercept) Residual\nStdDev: 2.80147e-05  0.22315\n\nFixed effects:  ch.cstock ~ years + years2 + dep1 + dep2 + ipcc.prec + ipcc.temp \n                   Value  Std.Error DF   t-value p-value\n(Intercept)    0.8533453 0.08722319 93  9.783468  0.0000\nyears         -0.0081524 0.00280862  9 -2.902638  0.0175\nyears2         0.0000594 0.00002376  9  2.500383  0.0338\ndep1           0.0168374 0.00290466 93  5.796695  0.0000\ndep2          -0.0001320 0.00003254 93 -4.056438  0.0001\nipcc.precwet  -0.0481100 0.06114358  9 -0.786836  0.4516\nipcc.tempwarm -0.0873289 0.05283942  9 -1.652722  0.1328\n Correlation: \n              (Intr) years  years2 dep1   dep2   ipcc.p\nyears         -0.752                                   \nyears2         0.677 -0.953                            \ndep1          -0.294 -0.074  0.055                     \ndep2           0.234  0.042 -0.028 -0.916              \nipcc.precwet  -0.484  0.414 -0.448 -0.130  0.109       \nipcc.tempwarm -0.386 -0.030 -0.016  0.098 -0.026  0.172\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.69345778 -0.68525693 -0.07894826  0.48777740  3.48592852 \n\nNumber of Observations: 142\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    34                     47 \n\n#____Remove ipcc.prec____\n\ntest.fit<-lme(ch.cstock~years+years2+dep1+dep2+ipcc.temp,\n\n              random = ~1|ran.exp/ran.yrexp, data = LU.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: LU.data \n       AIC      BIC   logLik\n  8.845024 35.44747 4.577488\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.08019223\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept) Residual\nStdDev: 1.994477e-05 0.223438\n\nFixed effects:  ch.cstock ~ years + years2 + dep1 + dep2 + ipcc.temp \n                   Value  Std.Error DF   t-value p-value\n(Intercept)    0.8200451 0.07637270 93 10.737411  0.0000\nyears         -0.0072352 0.00255963 10 -2.826678  0.0180\nyears2         0.0000510 0.00002127 10  2.397972  0.0374\ndep1           0.0165354 0.00287370 93  5.754030  0.0000\ndep2          -0.0001292 0.00003228 93 -4.003265  0.0001\nipcc.tempwarm -0.0800712 0.05215433 10 -1.535275  0.1557\n Correlation: \n              (Intr) years  years2 dep1   dep2  \nyears         -0.693                            \nyears2         0.588 -0.944                     \ndep1          -0.410 -0.023 -0.003              \ndep2           0.329 -0.003  0.023 -0.915       \nipcc.tempwarm -0.350 -0.113  0.069  0.123 -0.046\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.65812143 -0.68568772 -0.05351942  0.53865794  3.50204247 \n\nNumber of Observations: 142\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    34                     47 \n\n###Keep ipcc.pre out\n\n#____Remove ipcc.temp____\n\ntest.fit<-lme(ch.cstock~years+years2+dep1+dep2,\n\n              random = ~1|ran.exp/ran.yrexp, data = LU.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: LU.data \n       AIC      BIC   logLik\n  9.159036 32.80565 3.420482\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.09172667\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept)  Residual\nStdDev: 1.628889e-05 0.2227962\n\nFixed effects:  ch.cstock ~ years + years2 + dep1 + dep2 \n                 Value  Std.Error DF   t-value p-value\n(Intercept)  0.7804414 0.07372605 93 10.585695  0.0000\nyears       -0.0076584 0.00262714 11 -2.915094  0.0141\nyears2       0.0000529 0.00002195 11  2.412040  0.0345\ndep1         0.0169964 0.00284137 93  5.981773  0.0000\ndep2        -0.0001316 0.00003215 93 -4.092387  0.0001\n Correlation: \n       (Intr) years  years2 dep1  \nyears  -0.788                     \nyears2  0.653 -0.943              \ndep1   -0.379 -0.012 -0.009       \ndep2    0.321 -0.006  0.023 -0.915\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.75464698 -0.69354075 -0.06667757  0.56532555  3.53624701 \n\nNumber of Observations: 142\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    34                     47 \n\n###Leave out ipcc.temp, AIC only changed by 1 so it has no significant effects on the model\n\n#----Best Fit Land Use Model----\n\ntest.fit.LU<-lme(ch.cstock~years+years2+dep1+dep2,\n\n              random = ~1|ran.exp/ran.yrexp, data = LU.data, method = \"ML\", na.action = na.omit)\n\nsummary(test.fit.LU)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: LU.data \n       AIC      BIC   logLik\n  9.159036 32.80565 3.420482\n\nRandom effects:\n Formula: ~1 | ran.exp\n        (Intercept)\nStdDev:  0.09172667\n\n Formula: ~1 | ran.yrexp %in% ran.exp\n         (Intercept)  Residual\nStdDev: 1.628889e-05 0.2227962\n\nFixed effects:  ch.cstock ~ years + years2 + dep1 + dep2 \n                 Value  Std.Error DF   t-value p-value\n(Intercept)  0.7804414 0.07372605 93 10.585695  0.0000\nyears       -0.0076584 0.00262714 11 -2.915094  0.0141\nyears2       0.0000529 0.00002195 11  2.412040  0.0345\ndep1         0.0169964 0.00284137 93  5.981773  0.0000\ndep2        -0.0001316 0.00003215 93 -4.092387  0.0001\n Correlation: \n       (Intr) years  years2 dep1  \nyears  -0.788                     \nyears2  0.653 -0.943              \ndep1   -0.379 -0.012 -0.009       \ndep2    0.321 -0.006  0.023 -0.915\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.75464698 -0.69354075 -0.06667757  0.56532555  3.53624701 \n\nNumber of Observations: 142\nNumber of Groups: \n               ran.exp ran.yrexp %in% ran.exp \n                    34                     47 \n\n#______________________________________________________________________________________________\n\n### EF'S THEN CALCULATED IN EXCEL\n\n# Derive PDF for each model/EF\n\n###Land Use EF\n\nfixed.LU<-fixed.effects(test.fit.LU)\n\nLU.cov<-test.fit.LU$varFix\n\nx.LU<-c(1,75,5625,15,300)\n\n# Variance\n\nV.LU.EF<-(t(x.LU))%*%LU.cov%*%x.LU\n\n# Standard Deviation\n\nsqrt(V.LU.EF)\n\n           [,1]\n[1,] 0.03887679\n\n#_________________________________________\n\n###CInput EF\n\nfixed.Cinput<-fixed.effects(test.fit.CInput)\n\nCinput.cov<-test.fit.CInput$varFix\n\nX.Cinput.low<-c(1,1,75,15,300)\n\nX.Cinput.high<-c(1,0,75,15,300)\n\n# Variance\n\nV.Cinput.low<-(t(X.Cinput.low))%*%Cinput.cov%*%X.Cinput.low\n\nV.Cinput.high<-(t(X.Cinput.high))%*%Cinput.cov%*%X.Cinput.high\n\n# Standard Deviation\n\nsqrt(V.Cinput.low)\n\n           [,1]\n[1,] 0.05190687\n\nsqrt(V.Cinput.high)\n\n           [,1]\n[1,] 0.05707304\n\n#_________________________________________\n\n###Management EF\n\nfixed.management<-fixed.effects(test.fit.management)\n\nmanagement.cov<-test.fit.management$varFix\n\nx.rt.wet<-c(1,1,20,15,300,1)\n\nx.nt.wet<-c(1,0,20,15,300,1)\n\nx.nt.dry<-c(1,0,20,15,300,0)\n\nx.rt.dry<-c(1,1,20,15,300,0)\n\n# Variance\n\nv.rt.wet<-(t(x.rt.wet))%*%management.cov%*%x.rt.wet\n\nv.nt.wet<-(t(x.nt.wet))%*%management.cov%*%x.nt.wet\n\nv.nt.dry<-(t(x.nt.dry))%*%management.cov%*%x.nt.dry\n\nv.rt.dry<-(t(x.rt.dry))%*%management.cov%*%x.rt.dry\n\n# Standard Deviation\n\nsqrt(v.rt.wet)\n\n           [,1]\n[1,] 0.02827946\n\nsqrt(v.nt.wet)\n\n           [,1]\n[1,] 0.02364594\n\nsqrt(v.nt.dry)\n\n           [,1]\n[1,] 0.03007006\n\nsqrt(v.rt.dry)\n\n           [,1]\n[1,] 0.03158836\n\n#_____________Export CSV files with my covariance matrix to run in cholesky decomp model for monte carlo__________________\n\n###CSV files\n\n#write.csv(data.frame(LU.cov), \"LandUseCov.csv\")\n\n#write.csv(data.frame(Cinput.cov), \"CinputCov.csv\")\n\n#write.csv(data.frame(management.cov), \"MgmtCov.csv\")\n\n#NOTE: always keep dep1 and dep2 when testing the model w/ AIC value and years"
  },
  {
    "objectID": "Geospatial.html",
    "href": "Geospatial.html",
    "title": "Geospatial Data Analysis",
    "section": "",
    "text": "This is an exercise from a course taken during my Masters program. This problem set involved analyzing species occurrence data in conjunction with river distribution in Colorado. The R script below shows multiple mapping projections, spatial analysis, and calculations for species populations.\n\nGeospatial R Script"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Greenhouse Gas Accounting Portfolio",
    "section": "",
    "text": "Welcome to my portfolio! My name is Natalie Wiley and I’m excited to meet you.\nI am a soon-to-be graduate with a Professional Science Masters in Ecosystem Sustainability, focusing on Carbon management. I am avid birder, mountain biker, and I enjoy doing wildlife photography. As an early-career professional, my expertise lies in greenhouse gas accounting and sustainability!"
  },
  {
    "objectID": "N2O_SoilEmissions.html",
    "href": "N2O_SoilEmissions.html",
    "title": "Soil N2O Emissions-Regression Model",
    "section": "",
    "text": "This project contains two parts. The firs part estimates carbon stock change factors (i.e., emission factors) for tillage management and a developed Tier 3 regression model for soil N2O emissions through an analysis of measurement data.  I derived Tier 2 emission factors using simple averages and linear regression models.\n\nThe second part of this project fits the Tier 3 regression model from part 1 based on measured N2O emissions. An R script function was created to estimate emissions from soil carbon stock changes.\nPart 1: Emission Factor Development R Script\n\nlibrary(nlme)\n\n###### Management Factor\n# Read data from csv file\nmanagement.data<-read.csv(\"SoilCManagement.csv\", header=TRUE)\n\n# test for correlation in predictor variables\ncor(management.data[,c(\"years\", \"dep1\", \"dep2\")])\n\n# fit full model with all variables as main effects for input\ntest.fit<-lme(ch.cstock~ch.till+years+years2+dep1+dep2+moisture+temp, random=~1 | ran.exp/ran.yrexp, \n              data=management.data, method=\"ML\", na.action=na.omit)\nsummary(test.fit)\n\n# Diagnostic Plots, Residual Plot\nresid<-residuals(test.fit)\nplot(fitted(test.fit), resid)\nabline(0,0)\n\n# QQ normal plot\nqqnorm(resid)\nqqline(resid)\n\n\n# Full model\ntest.fit<-lme(ch.cstock~ch.till+years+years2+dep1+dep2+moisture+temp, random=~1 | ran.exp/ran.yrexp, \n              data=management.data, method=\"ML\", na.action=na.omit)\n\n# Backward stepwise fit method\ntest.fit<-lme(ch.cstock~ch.till+years+dep1+dep2+moisture+temp, random=~1 | ran.exp/ran.yrexp, \n              data=management.data, method=\"ML\", na.action=na.omit)\n\ntest.fit<-lme(ch.cstock~ch.till+years+dep1+dep2+moisture, random=~1 | ran.exp/ran.yrexp, \n              data=management.data, method=\"ML\", na.action=na.omit)\n\nsummary(test.fit)\n\n# Test interactions\ntest.fit<-lme(ch.cstock~ch.till+years+dep1+dep2+moisture+ ch.till*years+ch.till*dep1+\n                ch.till*dep2+ch.till*moisture+years*dep1+years*dep2+years*moisture+\n                dep1*moisture+dep2*moisture, random=~1 | ran.exp/ran.yrexp, \n              data=management.data, method=\"ML\", na.action=na.omit)\n\ntest.fit<-lme(ch.cstock~ch.till+years+dep1+dep2+moisture+ ch.till*years+ch.till*dep1+\n                ch.till*dep2+ch.till*moisture+years*dep1+years*dep2+\n                dep1*moisture+dep2*moisture, random=~1 | ran.exp/ran.yrexp, \n              data=management.data, method=\"ML\", na.action=na.omit)\n\ntest.fit.management<-lme(ch.cstock~ch.till+years+dep1+dep2+moisture+ ch.till*years+ch.till*dep1+\n                ch.till*dep2+years*dep1+years*dep2+\n                dep1*moisture+dep2*moisture, random=~1 | ran.exp/ran.yrexp, \n              data=management.data, method=\"REML\", na.action=na.omit)\nsummary(test.fit.management)\n\n\n# Derive PDF\nfixed.management<-fixed.effects(test.fit.management)\nmanagement.cov<-test.fit.management$varFix\n\n# Variables\nx.rt.wet<-c(1,1,20,15,300,1,20,15,300,300,6000,15,300)\nx.rt.dry<-c(1,1,20,15,300,0,20,15,300,300,6000,0,0)\n\nx.nt.wet<-c(1,0,20,15,300,1,0,0,0,300,6000,15,300)\nx.nt.dry<-c(1,0,20,15,300,0,0,0,0,300,6000,0,0)\n\n# Estimates\nt(x.rt.wet)%*%fixed.management\nt(x.rt.dry)%*%fixed.management\nt(x.nt.wet)%*%fixed.management\nt(x.nt.dry)%*%fixed.management\n\n# Variance\nv.rt.wet<-(t(x.rt.wet)%*%management.cov%*%x.rt.wet)\nv.rt.dry<-(t(x.rt.dry)%*%management.cov%*%x.rt.dry)\nv.nt.wet<-(t(x.nt.wet)%*%management.cov%*%x.nt.wet)\nv.nt.dry<-(t(x.nt.dry)%*%management.cov%*%x.nt.dry)\n\n# Standard Deviation\nsqrt(v.rt.wet)\nsqrt(v.rt.dry)\nsqrt(v.nt.wet)\nsqrt(v.nt.dry)\n\n\n\nPart 2: Soil N2O Emissions Estimation R Script\n\n\"SynFert.N2O.emissions.Regression\"<-\n  function(mineralN.amount=75, mineralN.amount.sd=5, beta= a, cov.beta=b, MAPPET=1, nreps=10000, iseed=230984, return.option=1)\n    # Script developed by Natalie Wiley\n    # Originally developed: 3/2/2022\n    # Last updated:\n    # Script estmates N2O emissions (kg CO2 eq. per ha per yr) from mineral N fertilization\n    ### Arguments\n    # mineralN.amount      The amount of mineral N fertilizer added to soil (Kg N per HA)\n    # mineralN.amount.sd   Standard deviation of the N mineral fertilizer amount\n    # MAPPET               Mean annual precipitation to potential evapotranspiration ratio\n    # beta                 R object with betas from LME model\n    # cov.beta             R object with covriance matrix for betas from LME model\n    # nreps                Number of monte carlo simulations\n    # iseed                 Initial seed for random draws\n    # return.option        1) list object with the emission mean and confidence intervals for N2O emissions, and\n    #                      2) the full vector of all Monte Carlo simulations\n##\n##### Begin Script\n  {\n##### Set seed\n    set.seed(iseed)\n##### Check validity of input variables\n    # values equal to or greater than 0 are valid\n    check.mineralN.amount<-mineralN.amount>=0&mineralN.amount<=880\n    if(!check.mineralN.amount){stop(\"MineralN amount is not valid.\")\n    } else {cat(\"NOTE: Mineral N amount is valid\")}\n    \n\n    check.mineralN.amount.sd<-mineralN.amount.sd>=0\n    if(!check.mineralN.amount.sd){stop(\"MineralN sd is not valid.\")\n    } else {cat(\"NOTE: Mineral N sd is valid\")}\n    \n    \n    check.MAPPET<-MAPPET>=0.7&MAPPET<=3.3\n    if(!check.MAPPET){stop(\"MAP:PET ratio is not valid.\")\n    } else {cat(\"NOTE: MAP:PET is valid\")}\n    \n    # End Validity Checks\n    ##\n##### Estimate direct N2O emissions using linear mixed effect model\n    # Deterministic Calculation\n    # estimate emissions and backtransform (since we had to transform our data to be homogenous and use a log transformation, we now have to backtransform a log # into regular units)\n    direct.emission.deterministic.ln<-beta%*%t(cbind(1, mineralN.amount,MAPPET))\n    direct.emission.deterministic<- (exp(direct.emission.deterministic.ln)) * (44/28) * 298\n    \n    # Probabilistic calculation\n    # Simulate nreps of fertilizer amounts\n    mineralN.amount.sim <- rnorm(nreps, mean = mineralN.amount, sd = mineralN.amount.sd)\n    \n    # Simulate nreps of beta parameters based on LME model\n    # determine number of parameters\n    numpar<-length(beta) #number of parameters in the model\n    \n    # computer choleski decomposition \n    M<-t(chol(cov.beta))\n    #\n    # generate random normals\n    z<-matrix(rnorm(nreps*numpar), numpar, nreps)\n    \n    # produce simulated betas\n    sim.beta<-M%*%z+beta\n  }"
  },
  {
    "objectID": "Risk_Assessment.html",
    "href": "Risk_Assessment.html",
    "title": "Risk Analysis for Transportation Emission Reduction Policies",
    "section": "",
    "text": "This project consisted of a risk analysis assessment for two hypothetical emission reduction plans for the city of Fort Collins, CO. This risk analysis quantified the amount of CO2e emissions reduced so I could show which policy plan achieved the most emissions reduced per tax dollar spent. In both hypothetical options, there was a budget of $500,000 to cut emissions from residential transportation.\nPolicy option 1: Buy back vehicles that are trucks (not large commercial trucks), SUVs, or sedans, to have residents purchase an electric vehicle. This program is targeting older vehicles in the fleet for the buy-back program because the incentives are too low for owners to participate that have newer vehicles.\n\nThe goal is to determine the amount of people that would participate in the buy back program from each population demographic (gender, education, age, reason for travel, vehicle type (SUV, sedan, truck).\n\nPolicy option 2: Small businesses are provided a $5,000 incentive and recognition as a climate smart company to support telecommuting by employees for two or more days of the week. This would reduce the amount of vehicle trips per week.\n\nThe goal is to see how many people and how many businesses would likely participate in the program\n\n\nResults\n\nThe cost to reduce CO2e in both policy options were too high. The dollar amount cost per 1 tonne of emissions reduced was not worth investing $500,000 in. It is higher than the current social cost of carbon.\n\n\n\n\n\nR Script to assess policy option 1\n\n####Import data contains weekly emission REDUCTIONS because we worked in Access to see how much emission reduction we \n  ###would get if we switched people over to EVs\n\n#ID is the ID number associated with each survey respondent \n#### size = 108 = average of quotas for all three vehicles = mean (c(125,90,111))\n\n### ASSUMPTIONS:\n#weekend emissions: multiply weekly emissions by 33%  and add that as the weekend emission\n#example: to sample just SUVs instead of all cars, only have SUVs in your input table in Access (subset table to SUVs only, subset function can be done in R)\n#make points in presentation about the risk and what we can get from the different programs\n\n\n#Add packages\nlibrary(tidyverse)\n  \n# Arguments\niseed = 34\nnreps = 5\nbuyback_sample_size = 108\n\n    \nset.seed(iseed)\n\n#import vehile emissions data\nsurvey_data<-read.csv(file= \"InputData.csv\" , header=TRUE, sep=\",\", fill= FALSE)\n\n# Covert the weekly emission reductions to annual\nsurvey_data[,11]= survey_data[,11]*52\n\n# Convert your now yearly emission reductions from kg to MT\nsurvey_data[,11]= survey_data[,11]*0.001\n\n#____________ Sample Buyback vehicles based on variable probabilities ______________\n\n# sampling vehicles in buyback program by vehicle type probability\n#### size = 108 = average of quotas for all three vehicles = mean (c(125,90,111))\n#### Put the sample function within the forloop in order to do monte carlo iterations while you sample the amount of cars we can buy back with $500,000 budget\n\nMTCO2_reduced_allvehicles<-matrix(0, nrow = nreps, ncol = 2)\nfor (car in (1:nreps)) {\n  #this line samples 108 vehicles from the 3196 population available (from access input file)\n  sample_vehicles<-sample(x = survey_data$ID, size = buyback_sample_size , replace = FALSE, prob = (survey_data[,6]))\n  # this line connects the survey data (info about reductions) with the ID of the records you sampled\n  join_vehicle_type<-survey_data[survey_data$ID %in% sample_vehicles,]\n  # this line sums the emission reductions from all samples\n  MTCO2_reduced_allvehicles[car,1]<-sum(join_vehicle_type[,11])\n  # this line divides the cost of vehicles by the sum of emission reductions ($/MT reduced annually)\n  MTCO2_reduced_allvehicles[car,2]<-(sum(join_vehicle_type[,10]))/(sum(join_vehicle_type[,11]))\n}\n\n# Calculate emissions reduced mean and confidence interval\nmean(MTCO2_reduced_allvehicles[,1])\nquantile(MTCO2_reduced_allvehicles[,1], probs =  c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval\nmean(MTCO2_reduced_allvehicles[,2])\nquantile(MTCO2_reduced_allvehicles[,2], probs =  c(0.025,0.975))\n\n#sampling specific vehicles now to see if there are more emission reductions: SEDAN\n\nsedans<-subset(survey_data, survey_data$VehicleType==\"Sedan\")\n\nemission.reduced.sedans<-matrix(0, nrow = nreps, ncol = 2)\nfor (s in 1:nreps) {\n  sedan.vehicles<-sample(sedans$ID,125,replace = FALSE)\n  Buyback.sedans<-sedans[sedans$ID %in% sedan.vehicles,]\n  emission.reduced.sedans[s,1]<- sum(Buyback.sedans$Total_Week_EmissionReduction_kgCO2)\n  # this line divides the cost of vehicles by the sum of emission reductions ($/MT reduced annually)\n  emission.reduced.sedans[s,2]<-(sum(join_vehicle_type[,10]))/(sum(join_vehicle_type[,11]))\n}\n\n# Calculate emissions reduced mean and confidence interval - SEDANS\nmean(emission.reduced.sedans[,1])\nquantile(emission.reduced.sedans[,1], probs =  c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval - SEDANS\nmean(emission.reduced.sedans[,2])\nquantile(emission.reduced.sedans[,2], probs =  c(0.025,0.975))\n\n\n#sampling specific vehicles now to see if there are more emission reductions: TRUCK\n\ntrucks<-subset(survey_data, survey_data$VehicleType==\"Truck\")\n\n\nemission.reduced.trucks<-matrix(0, nrow = nreps, ncol = 2)\nfor (t in 1:nreps) {\n  truck.vehicles<-sample(trucks$ID,111,replace = FALSE)\n  Buyback.trucks<-trucks[trucks$ID %in% truck.vehicles,]\n  emission.reduced.trucks[t,1]<- sum(Buyback.trucks$Total_Week_EmissionReduction_kgCO2)\n  # this line divides the cost of vehicles by the sum of emission reductions ($/MT reduced annually)\n  emission.reduced.trucks[t,2]<-(sum(join_vehicle_type[,10]))/(sum(join_vehicle_type[,11]))\n}\n\n# Calculate emissions reduced mean and confidence interval - TRUCKS\nmean(emission.reduced.trucks[,1])\nquantile(emission.reduced.trucks[,1], probs =  c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval - TRUCKS\nmean(emission.reduced.trucks[,2])\nquantile(emission.reduced.trucks[,2], probs =  c(0.025,0.975))\n\n#sampling specific vehicles now to see if there are more emission reductions: SUV\nSUVs<-subset(survey_data, survey_data$VehicleType==\"SUV\")\n\nemission.reduced.SUV<-matrix(0, nrow = nreps, ncol = 2)\nfor (v in 1:nreps) {\n  SUV.vehicles<-sample(SUVs$ID,125,replace = FALSE)\n  Buyback.SUV<-SUVs[SUVs$ID %in% SUV.vehicles,]\n  emission.reduced.SUV[v,1]<-sum(Buyback.SUV$Total_Week_EmissionReduction_kgCO2)\n  # this line divides the cost of vehicles by the sum of emission reductions ($/MT reduced annually)\n  emission.reduced.SUV[v,2]<-(sum(join_vehicle_type[,10]))/(sum(join_vehicle_type[,11]))\n}\n# Calculate emissions reduced mean and confidence interval - SUV\nmean(emission.reduced.SUV[,1])\nquantile(emission.reduced.SUV[,1], probs =  c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval - SUV\nmean(emission.reduced.SUV[,1])\nquantile(emission.reduced.SUV[,2], probs =  c(0.025,0.975))\n\n# sampling vehicles in buyback program by age probability\n\nEmissions_reduced_age<-matrix(0, nrow = nreps, ncol = 2)\nfor (car in (1:nreps)) {\n  vehicle_age_sample<-sample(x = survey_data$ID, size = buyback_sample_size , replace = FALSE, prob = (survey_data[,7]))\n  join_age<-survey_data[survey_data$ID %in% vehicle_age_sample,]\n  Emissions_reduced_age[car,1]<-sum(join_age[,11])\n  Emissions_reduced_age[car,2]<-(sum(join_age[,10]))/(sum(join_age[,11]))\n}\n\n# Calculate emissions reduced mean and confidence interval\nmean(Emissions_reduced_age[,1])\nquantile(Emissions_reduced_age[,1], probs = c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval\nmean(Emissions_reduced_age[,2])\nquantile(Emissions_reduced_age[,2], probs = c(0.025,0.975))\n\n# sampling vehicles in buyback program by education probability\n\nEmissions_reduced_edu<-matrix(0, nrow = nreps, ncol = 2)\nfor (car in (1:nreps)) {\n  vehicle_edu_sample<-sample(x = survey_data$ID, size = buyback_sample_size , replace = FALSE, prob = (survey_data[,9]))\n  join_edu<-survey_data[survey_data$ID %in% vehicle_edu_sample,]\nEmissions_reduced_edu[car,1]<-sum(join_edu[,11])\nEmissions_reduced_edu[car,2]<-(sum(join_edu[,10]))/(sum(join_edu[,11]))\n}\n\n# Calculate emissions reduced mean and confidence interval\nmean(Emissions_reduced_edu[,1])\nquantile(Emissions_reduced_edu[,1], probs = c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval\nmean(Emissions_reduced_edu[,2])\nquantile(Emissions_reduced_edu[,2], probs = c(0.025,0.975))\n\n\n\nR Script to assess policy option 2\n\n#Set up dsata frame with business data and propoabilities of employees staying home, and how many already telework\n### Note: 100 businesses can participate in program given the $5,000 incentive with the $500,000 budget\n\nnreps=5\niseed=1234\nset.seed(iseed)\n\nsmallbus<-data.frame(\"ID\"= 1:11503, \"Type\"=\"S\", \"Min\"=1, \"Max\"=10, \"PropTC\"=0.09, \"ProbPart\"=0.09)\nmedbus<-data.frame(\"ID\"= 11504:15157, \"Type\"=\"M\", \"Min\"=11, \"Max\"=30, \"PropTC\"=0.031, \"ProbPart\"=0.12)\nlargebus<-data.frame(\"ID\"= 15157:15660, \"Type\"=\"L\", \"Min\"=31, \"Max\"=50, \"PropTC\"=0.064, \"ProbPart\"=0.17)\nbusinesses_data<-rbind(smallbus,medbus,largebus)\n\n#import emissions  (contains weekly emissions, and emission reductions from not communting to work 2-5 days)\nWork_commute_data<-read.csv(file= \"GreenBusinessData.csv\" , header=TRUE, sep=\",\", fill= FALSE)\n\n# Covert the weekly emission reductions to annual\nWork_commute_data[,8]= Work_commute_data[,8]*52\n\n# Convert your now yearly emission reductions from kg to MT\nWork_commute_data[,8]= Work_commute_data[,8]*0.001\n\n#Randomly select businesses and determine # of additional employees that will telework in a nested forloop to sample \n\nSelected_Businesses<-matrix(0, nrow = 100, ncol = 1)\nSelected_employees<-matrix(0, nrow = 100, ncol = 1)\npeople<-matrix(0, nrow = nreps, ncol = 1)\nfor (a in 1:nreps) {\n  Businesses<-sample(businesses_data$ID, size = 100, replace = F, prob = businesses_data$probPart)\n  join<-businesses_data[businesses_data$ID %in% Businesses,]\n  for (b in 1:100) {\n    Selected_Businesses[b,]<-sample(join[b,3]:join[b,4], size = 1)\n    Selected_employees<-Selected_Businesses-join[b,5]*Selected_Businesses\n    Selected_employees<-round(Selected_employees)\n  }\n  people[a,1]<-sum(Selected_employees)\n}\n\n#Make for loop like the ones from the buy back program, sample telecomuting emissions$ID, sample size is the people selected in the nested forloop above\n\n### Sample for 2 days of working remotely\nEmissions_reduced_2days<-matrix(0,nrow = nreps, ncol = 2)\nfor (t in (1:nreps)) {\n  people_sample<-sample(x=Work_commute_data$ID, size = Selected_employees[t,], replace = TRUE)\n  join_emissions<-Work_commute_data[Work_commute_data$ID %in% people_sample,]\n  Emissions_reduced_2days[t,1]<-sum(join_emissions[,9])\n  Emissions_reduced_2days[t,2]<-500000/sum(join_emissions[,9])\n  \n}\n\n# Calculate 2day emissions reduced mean and confidence interval\nmean(Emissions_reduced_2days[,1])\nquantile(Emissions_reduced_2days[,1], probs =  c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval\nmean(Emissions_reduced_2days[,2])\nquantile(Emissions_reduced_2days[,2], probs =  c(0.025,0.975))\n\n### Sample for 3 days of working remotely\nEmissions_reduced_3days<-matrix(0,nrow = nreps, ncol = 2)\nfor (t in (1:nreps)) {\n  people_sample<-sample(x=Work_commute_data$ID, size = Selected_employees[t,], replace = TRUE)\n  join_emissions<-Work_commute_data[Work_commute_data$ID %in% people_sample,]\n  Emissions_reduced_3days[t,1]<-sum(join_emissions[,10])\n  Emissions_reduced_3days[t,2]<-500000/sum(join_emissions[,10])\n  \n}\n\n# Calculate 3day emissions reduced mean and confidence interval\nmean(Emissions_reduced_3days[,1])\nquantile(Emissions_reduced_3days[,1], probs =  c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval\nmean(Emissions_reduced_3days[,2])\nquantile(Emissions_reduced_3days[,2], probs =  c(0.025,0.975))\n\n### Sample for 4 days of working remotely\nEmissions_reduced_4days<-matrix(0,nrow = nreps, ncol = 2)\nfor (t in (1:nreps)) {\n  people_sample<-sample(x=Work_commute_data$ID, size = Selected_employees[t,], replace = TRUE)\n  join_emissions<-Work_commute_data[Work_commute_data$ID %in% people_sample,]\n  Emissions_reduced_4days[t,1]<-sum(join_emissions[,11])\n  Emissions_reduced_4days[t,2]<-500000/sum(join_emissions[,11])\n  \n}\n\n# Calculate 4day emissions reduced mean and confidence interval\nmean(Emissions_reduced_4days[,1])\nquantile(Emissions_reduced_4days[,1], probs =  c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval\nmean(Emissions_reduced_4days[,2])\nquantile(Emissions_reduced_4days[,2], probs =  c(0.025,0.975))\n\n### Sample for 5 days of working remotely\nEmissions_reduced_5days<-matrix(0,nrow = nreps, ncol = 2)\nfor (t in (1:nreps)) {\n  people_sample<-sample(x=Work_commute_data$ID, size = Selected_employees[t,], replace = TRUE)\n  join_emissions<-Work_commute_data[Work_commute_data$ID %in% people_sample,]\n  Emissions_reduced_5days[t,1]<-sum(join_emissions[,12])\n  Emissions_reduced_5days[t,2]<-500000/sum(join_emissions[,12])\n  \n}\n\n# Calculate 5day emissions reduced mean and confidence interval\nmean(Emissions_reduced_5days[,1])\nquantile(Emissions_reduced_5days[,1], probs =  c(0.025,0.975))\n\n# Calculate $/MT emissions reduced mean and confidence interval\nmean(Emissions_reduced_5days[,2])\nquantile(Emissions_reduced_5days[,2], probs =  c(0.025,0.975))"
  },
  {
    "objectID": "SOC_change_montecarlo.html",
    "href": "SOC_change_montecarlo.html",
    "title": "Soil Organic Carbon Stock Change",
    "section": "",
    "text": "This R Script estimates the change in soil organic carbon stock in cropland soils between 2005 and 2010. This function uses a Monte Carlo analysis methods from the 2006 IPCC guidelines. This estimation looks at the carbon stock changes among different crop management types such as full and no till including levels of C input.\n\n\"SOC.stockdif\"<-function(crop.expert.data=\"expertdata.csv\", land.use.beta=\"cult \n                         .betas.csv\", land.use.cov=\"LandUseCov.csv\", mgmtbeta=\"mgmt\n                         .betas.csv\", mgmtcov= \"MgmtCov.csv\", C.input.beta=\"input\n                         .betas.csv\", C.input.cov=\"CinputCov.csv\", x.variables=\"x\n                         .variables.csv\", SOC.ref=80, SOC.ref.sd=36, cropland.area\n                         =56890,cropland.area.sd=2845, D = 20, nreps = 10, iseed\n                         =1234, ncases = 6,  EF.ft=1, EF.med.input = 1, \n                         nmitscenarios=1, return.option=1)\n\nThis is commented code to serve as descriptors for data types used within the function\n\n # Script developed by N Wiley\n  # Originally Developed: September 27, 2022\n  # Last Update: October 20, 2022 \n  #\n  \n  #Script estimates the SOC stock change different in cropland soils between 2005 and 2020, also showing SOC changes w/\n      #different management types (full till, no till,) and level of input (low, med, high)\n  \n  \n####### Arguments\n# crop.expert.data      Input file in csv format with data given in proportions of land within defined management cases\n# iseed                 Initial seed value for random draws\n# nreps                 Number of Monte Carlo iterations\n# ncases                Number of Management cases from the expert data\n# beta                  Parameter from lME model used to derive emission factors\n# cov.matrix            Matrix with covariance from LME model used to derive emission factors\n# D                     Stock change dependence (years) (20 comes from IPCC guidelines VOL 4 ch 2)\n# SOC.ref                Reference soil carbon stock\n# SOC.ref.sd             Error associated with soil carbon stock\n# cropland.area                  Land area (hectares)\n# cropland.area.sd               Error associated with area\n# return.option         \n##\n\n\n#___________ Begin Script ___________\n\n{  \n  # Set Seed\n  set.seed(iseed)\n  \n  # Load Library\n  \n  #___________ Import Data ____________\n  \n  expert.data<-read.csv(file=crop.expert.data, header=TRUE, sep=\",\", fill=FALSE)\n  \n  ##Import Betas for EF's\n  landuse.beta<-read.csv(file=land.use.beta, header=F, sep=\",\")\n  #landuse.beta<-c(landuse.beta[1,])\n  LU.beta<-as.vector(landuse.beta)\n  #landuse.beta<-c(land.use.beta[,1])\n  mgmt.beta<-read.csv(file=mgmtbeta, header=F, sep=\",\", fill=FALSE )\n  #mgmt.beta<-c(mgmtbeta[,1])\n  Cinput.beta<-read.csv(file=C.input.beta, header=F, sep=\",\", fill=FALSE)\n  #Cinput.beta<-c(C.input.beta[,1])\n  \n  landuse.cov<-read.csv(file=landuse.cov, header=F, sep=\",\", fill=FALSE)\n  mgmt.cov<-read.csv(file=mgmtcov, header=F, sep=\",\", fill=FALSE)\n  Cinput.cov<-read.csv(file=Cinput.cov, header=F, sep=\",\", fill=FALSE)\n  \n  x.variables<-read.csv(file=x.variables, header=TRUE, sep=\",\", fill=FALSE)\n\n\n #______________ Create Checks ________________\n  \n  # Check that cropland area and uncertainty is greater than 0\n  check.cropland.area<-cropland.area>=0\n  if(!check.cropland.area) {stop(\"Cropland area is not greater than 0.\")}\n  check.cropland.area.sd<-cropland.area.sd>=0\n  if(!check.cropland.area.sd) {stop(\"Cropland area standard deviation is not greater than 0.\")}\n  \n  # Check that SOC.ref and uncertainty is greater than 0\n  check.SOC.ref<-SOC.ref>=0\n  if(!check.SOC.ref) {stop(\"SOC reference stock is not greater than 0.\")}\n  check.SOC.ref.sd<-SOC.ref.sd>=0\n  if(!check.SOC.ref.sd) {stop(\"SOC reference stock standard deviation is not greater than 0.\")}\n  \n  # Check that proportion amounts equal 1 in each year for each expert\n  \n  \n  #______________ Probabilistic draws for Monte Carlo Simulation_______________\n  \n  # Simulate nreps for SOC.ref\n  \n  SOC.ref.sim<-rnorm(nreps, mean = SOC.ref, sd=SOC.ref.sd)\n#  SOC.ref.sim<-as.matrix(t(SOC.ref.sim))\n  \n  # Simulate nreps for cropland.area\n  \n  area.sim<-rnorm(nreps, mean = cropland.area, sd=cropland.area.sd)\n # area.sim<-as.matrix(area.sim)\n  \n  # Draw samples from expert proportions (expert.data)\n  \n  #expert.sim<-matrix(0,ncol = nreps, nrow = 12)\n  expert.sim<-expert.data[sample(ncol(expert.data), size = nreps, replace = TRUE)]\n\n\n #______________ Estimate Area _____________\n  \n  area.prop.comb<-sweep(expert.sim, MARGIN=2, area.sim, '*')\n  \n  #These parameters come from the previous LME models to create EF betas and covariances\n  \n  # Determine number of parameters for each EF\n  numpar.landuse<-length(landuse.beta)\n  numpar.mgmt<-length(mgmt.beta)\n  numpar.Cinput<-length(Cinput.beta)\n  \n  # Compute Cholesky decomposition for each EF\n  chol.decomp.landuse<-t(chol(landuse.cov))\n  chol.decomp.mgmt<-t(chol(mgmt.cov))\n  chol.decomp.Cinput<-t(chol(Cinput.cov))\n  \n  # Generate random draws of 0 for each EF in a normal distribution\n\n  random.landuse<-matrix(rnorm(nreps*numpar.landuse),numpar.landuse,nreps)\n  random.mgmt<-matrix(rnorm(nreps*numpar.mgmt),numpar.mgmt,nreps)\n  random.Cinput<-matrix(rnorm(nreps*numpar.Cinput),numpar.Cinput,nreps) \n  \n  # Simulated betas\n  \n  landuse.EF.beta.sim.intermediatecalc<-(chol.decomp.landuse%*%random.landuse)\n  landuse.EFbeta.sim<-matrix(0, nrow=5, ncol=nreps)\n  for (e in 1:nreps) {\n    landuse.EFbeta.sim[,e]<- ((landuse.EF.beta.sim.intermediatecalc[,e]+landuse.beta[,e]))\n    \n  }\n  mgmt.EF.beta.sim<-(chol.decomp.mgmt%*%random.mgmt)+mgmt.beta\n  Cinput.EF.beta.sim<-(chol.decomp.Cinput%*%random.Cinput)+Cinput.beta\n  \n  \n \n  # __________ Estimate Emission Factors __________ (EF = intercept + B1X1) --> put x.cult in model (create csv and import) - then check to make sure that EF reps fit within the CI\n  \n  # Predictor variables from Assignment 2\n  # only need wet factors, not dry, because soils are in only a wet climate (don't use dry factors!)\n  \n  x.landuse<-as.matrix(x.variables[,1])\n  x.landuse<-na.omit(x.landuse)\n  x.rt.wet<-as.vector(x.variables[,2])\n  x.rt.wet<-na.omit(x.rt.wet)\n  x.nt.wet<-as.vector(x.variables[,3])\n  x.nt.wet<-na.omit(x.nt.wet)\n  x.low<-as.vector(x.variables[,4])\n  x.low<-na.omit(x.low)\n  x.high<-as.vector(x.variables[,5])\n  x.high<-na.omit(x.high)\n  \n  \n  # Land use EF reps\n  # The sweep function multiples the beta sim with the predictor variables to get the components of the EF\n  \n  \n  \n # EF.landuse.sweep<-sweep(landuse.EFbeta.sim, 1, x.landuse, \"*\")\n  #EF.landuse<-apply(EF.landuse.sweep, MARGIN = 1, FUN = sum)\n # EF.landuse<-as.matrix(t(EF.landuse))\n  \nEF.landuse<-matrix(0, nrow=numpar.landuse, ncol=nreps)\nfor (e in 1:nreps) {\n  EF.landuse[,e]<-(landuse.EFbeta.sim[e,]*x.landuse)\n  \n}\n  \n  \n  \n  # Management EF reps\n  \n  \n  EF.rt.wet.sweep<-sweep(mgmt.EF.beta.sim, 1, x.rt.wet, \"*\")\n  EF.rt.wet<-apply(EF.rt.wet.sweep, MARGIN = 2, FUN = sum)\n  EF.rt.wet<-as.matrix(t(EF.rt.wet))\n  \n  EF.nt.wet.sweep<-sweep(mgmt.EF.beta.sim, 1, x.nt.wet, \"*\")\n  EF.nt.wet<-apply(EF.nt.wet.sweep, MARGIN = 2, FUN = sum)\n  EF.nt.wet<-as.matrix(t(EF.nt.wet))\n  \n  # CInput EF reps\n\n  \n  EF.low.sweep<-sweep(Cinput.EF.beta.sim, 1, x.low, \"*\")\n  EF.low<-apply(EF.low.sweep, MARGIN = 2, FUN = sum)\n  EF.low<-as.matrix(t(EF.low))\n  \n  EF.high.sweep<-sweep(Cinput.EF.beta.sim, 1, x.high, \"*\")\n  EF.high<-apply(EF.high.sweep, MARGIN = 2, FUN = sum)\n  EF.high<-as.matrix(t(EF.high))\n\n\n #______________ Probabilistic Results _______________\n  # SOC stock changes by case\n  \n  \n  # Case 1: low input, full till\n  SOC.low.ft<-matrix(0, nrow = 1, ncol= nreps)\n  for(r in (1:nreps)) {\n    SOC.low.ft[,r]<-((SOC.ref.sim[,r]*EF.landuse[,r]*EF.ft*EF.low[,r]*area.prop.comb[7,r])-\n                       (SOC.ref.sim[,r]*EF.landuse[,r]*EF.ft*EF.low[,r]*area.prop.comb[1,r]))/D\n  }\n  \n  # Case 2: low input, no till  \n  SOC.low.nt<-matrix(0, nrow = 1, ncol= nreps)\n  for(r in (1:nreps)) {\n    SOC.low.nt[,r]<-((SOC.ref.sim[,r]*EF.landuse[,r]*EF.nt.wet[,r]*EF.low[,r]*area.prop.comb[8,r])-\n                       (SOC.ref.sim[,r]*EF.landuse[,r]*EF.nt.wet[,r]*EF.low[,r]*area.prop.comb[2,r]))/D\n  } \n  \n  # Case 3: medium input, full till \n  SOC.med.ft<-matrix(0, nrow = 1, ncol= nreps)\n  for(r in (1:nreps)) {\n    SOC.med.ft[,r]<-((SOC.ref.sim[,r]*EF.landuse[,r]*EF.ft*EF.med.input*area.prop.comb[9,r])-\n                       (SOC.ref.sim[,r]*EF.landuse[,r]*EF.ft*EF.med.input*area.prop.comb[3,r]))/D\n  } \n  \n  # Case 4: medium input, no till\n  SOC.med.nt<-matrix(0, nrow = 1, ncol= nreps)\n  for(r in (1:nreps)) {\n    SOC.med.nt[,r]<-((SOC.ref.sim[,r]*EF.landuse[,r]*EF.nt.wet[,r]*EF.med.input*area.prop.comb[10,r])-\n                       (SOC.ref.sim[,r]*EF.landuse[,r]*EF.nt.wet[,r]*EF.med.input*area.prop.comb[4,r]))/D\n  } \n  \n  # Case 5: high input, full till    \n  SOC.high.ft<-matrix(0, nrow = 1, ncol= nreps)\n  for(r in (1:nreps)) {\n    SOC.high.ft[,r]<-((SOC.ref.sim[,r]*EF.landuse[,r]*EF.ft*EF.high[,r]*area.prop.comb[11,r])-\n                        (SOC.ref.sim[,r]*EF.landuse[,r]*EF.ft*EF.high[,r]*area.prop.comb[5,r]))/D\n  }   \n  \n  # Case 6: high input, no till\n  SOC.high.nt<-matrix(0, nrow = 1, ncol= nreps)\n  for(r in (1:nreps)) {\n    SOC.high.nt[,r]<-((SOC.ref.sim[,r]*EF.landuse[,r]*EF.nt.wet[,r]*EF.high[,r]*area.prop.comb[12,r])-\n                        (SOC.ref.sim[,r]*EF.landuse[,r]*EF.nt.wet[,r]*EF.high[,r]*area.prop.comb[6,r]))/D\n  }   \n  \n  # Create results matrix\n  C.stockdif.total<-matrix(0, nrow = 1, ncol = nreps)\n  for (r in (1:nreps)) {\n    C.stockdif.total[,r]<-SOC.low.ft[,r]+SOC.low.nt[,r]+SOC.med.ft[,r]+SOC.med.nt[,r]+SOC.high.ft[,r]+SOC.high.nt[,r]\n  }\n  \n  #___________ Estimate means and confidence intervals of C stock change 2005-2020 ________\n  # Create matrix with col 1 = median, col 2 = 2.5 percentile, and col 3 = 97.5 percentile\n  \n  C.stockdif.results<-matrix(0, nrow = 1, ncol = 3)\n  C.stockdif.results[,1]<-mean(C.stockdif.total)\n  q<-quantile(C.stockdif.total, probs = c(0.025,0.975))\n  C.stockdif.results[,2]<-q[1]\n  C.stockdif.results[,3]<-q[2]\n  \n  \n  #___________ Return Statements ____________\n  \n  if(return.option ==1) {\n    return(list(\"Island X mean C stock change in mineral cropland soils (C tonnes /yr)\"=C.stockdif.results[,1],\n                \"2.5 percentile C stock change\"=C.stockdif.results[,2], \"97.5 percentile C stock change\"=C.stockdif.results[,3]))\n  }\n  if(return.option ==2) {\n    return(hist(x=C.stockdif.total, col = \"blue3\", main = \"Simulated SOC change for all replicates from Monte Carlo Simulation\", \n                xlab = \"SOC change replicates (C tonnes/yr)\", xlim= c(-50000,100000), labels = TRUE))\n  }\n  \n  #____________ End Script ________________\n  \n}"
  },
  {
    "objectID": "Transportation_Emissions.html",
    "href": "Transportation_Emissions.html",
    "title": "Transportation Emissions",
    "section": "",
    "text": "This project contains R script that estimates carbon dioxide (CO2), nitrous oxide (N2O), and methane (CH4) emissions from road transportation using default equations from 2006 IPCC guidelines vol 2 ch 3. This is a tier 2 GHG calculation with results in million metric tonnes.\n\nCO2 Transportation Emissions R Script\n\n\"CO2TransportEmissions\"<-\n    function(CO2.EF=69300, fuel.amount=1000) \n # Script developed by Natalie Wiley\n      # Originally Developed: February 11th, 2022\n      # Last Update: February 11th, 2022\n      ###### Arguments\n      #CO2.EF           CO2 emissions factor in kg/TJ\n      #fuel.amount      Amount of fuel in TJ\n      #\n      ###### Start Script\n    {\n      ###### Check Validity of Input Data\n      # Check that input fuel data are valid\n      check.fuel.amount<-fuel.amount>0\n      if(!check.fuel.amount) {stop(\"The amount of fuel must be greater than 0.\")}\n    \n      # check that CO2.EF is valid\n      check.CO2.EF<-CO2.EF>0\n      if(!check.CO2.EF) {stop(\"An individual emission factor has been entered - the EF must be greater than 0.\")}\n     \n      #\n      ###### Estimate CO2 emissions\n      # IPCC 2006 GL: CO2 emissions = fuel.amount * EF\n      # Units: CO2 emissions are in kg, fuel.amount is in TJ, and EF is in kg/TG\n      CO2.emissions.kg<-fuel.amount*CO2.EF\n      # convert into MMT\n      CO2.emissions.MMT<-CO2.emissions.kg/10^9\n      \n      ###### Check results\n      check.emission.amount<-CO2.emissions.MMT>0\n      if(!check.emission.amount) {stop(\"The amount of emissions must be greater than 0.\")\n        }\n      ###### Return Statement\n      return(list(\"CO2.emissions.MMT\"=CO2.emissions.MMT))\n      #\n      ###### End Script\n    }\n\n\n\nCH4 and N2O Transportation Emissions R Script\n\n\"CH4N2OTransportEmissions\"<-\n  function(input.filename=\"NAME\", vehicle.type=1)\n     # Script developed by Natalie Wiley\n      # Originally Developed: February 11th, 2022\n      # Last Update: February 11th, 2022\n  {\n    ###### Import files\n    #getwd()\n    input.data<-read.csv(file=input.filename,header=TRUE,sep=\",\", fill=FALSE)\n    #\n    ###### Check number of vehicle types in input file\n    check.type<-length(input.data[,1])==vehicle.type\n    if(!check.type) {stop(\"The number of vehicle types in the input file is not consistent with the number entered in the function argument\")\n    }\n    #\n    ###### Check Validity of Input Data\n    for(f in (1: vehicle.type)) {\n      check.fuel.amount<-input.data[f,2]>0\n      if(!check.fuel.amount){stop(\"Fuel amount must be greater than 0 - check input file.\")\n      }\n      check.CH4.ef<-input.data[f,3]>0\n      if(!check.CH4.ef){stop(\"Methane EF must be greater than 0 - Check input file.\")\n      }\n      check.N2O.ef<-input.data[f,4]>0\n      if(!check.N2O.ef){stop(\"Nitrous Oxide EF must be greater than 0 - Check input file.\")\n      }\n      \n    }\n    \n    #\n    ###### Calculate emissions\n    # IPCC 2006 GL: CH4 emissions = Fuel.amount * EF\n    # Units: CH4 emissions in kg, Fuel.amount in TJ and EF is kg/TJ\n    #\n    CH4.emissions.kg<-vector(mode = \"numeric\", length=vehicle.type)\n    for(ch in (1:vehicle.type)){\n      CH4.emissions.kg[ch]<- input.data[ch,2]*input.data[ch,3]\n    # Check Emissions\n      check.CH4.emissions.kg<-CH4.emissions.kg[ch]>0&CH4.emissions.kg[ch]<=10^12\n      if(!check.CH4.emissions.kg) {cat(\"Warning: Methane emissions are not within the expected range.\")\n        }\n    }\n    \n    # IPCC 2006 GL: N2O emissions = Fuel.amount * EF\n    # Units: N2O emissions in kg, Fuel.amount in TJ and EF is kg/TJ\n    #\n    N2O.emissions.kg<-vector(mode = \"numeric\", length=vehicle.type)\n    for(ch in (1:vehicle.type)){\n      N2O.emissions.kg[N]<- input.data[N,2]*input.data[N,4]\n    # Check Emissions\n      check.N2O.emissions.kg<-N2O.emissions.kg[N]>0&N2O.emissions.kg[N]<=10^12\n      if(!check.N2O.emissions.kg){cat(\"Warning: Nitrous Oxide emissions are not within the expected range.\")\n        }\n    }\n    \n    # Total emissions in CO2 equivalents\n    Total.CH4.TMT.CO2eq<-(sum(CH4.emissions.kg)/10^6)*25\n    Total.N2O.TMT.CO2eq<-(sum(N2O.emissions.kg)/10^6)*298\n    Total.CH4.N2O.MMT.CO2eq<-(Total.CH4.TMT.CO2eq+Total.N2O.TMT.CO2eq)/10^3\n    #\n    ###### Return Statement\n    return(list(\"Total.CH4.TMT.CO2eq\"=Total.CH4.TMT.CO2eq,\n                \"Total.N2O.TMT.CO2eq\"=Total.N2O.TMT.CO2eq,\n                \"Total.CH4.N2O.MMt.CO2eq\"=Total.CH4.N2O.MMt.CO2eq))\n    #\n    ###### End Script\n    }"
  },
  {
    "objectID": "Urea_Emissions.html",
    "href": "Urea_Emissions.html",
    "title": "Urea Emissions Estimation",
    "section": "",
    "text": "This R Script uses a function that estimates CO2e emissions from urea fertilizer application across all 50 US states using methodology from the 2006 IPCC Guidelines.\nThis estimation returns gigagrams CO2e emissions for each state and then US totals for the years 1990-2020\n\nUreaEmissionsUS<-\n  function(input.filename=\"NAME\", nyears=1, nstates=1, EF.mean=1, EF.min=1, EF.max=1, iseed=1234, nreps=10000)\n    #Script Developed by: N Wiley\n   # Originally Developed: August 24th, 2022\n    # Last Update:\n    # Script estimates CO2 emissions from urea fertilizer application across all 50 US states using Tier methodology from the 2006 IPCC Guidelines\n    #Returns Gigagrams CO2 emissions for each state and then US totals for the years 1990-2020\n    # Input.filename was originially in units of N fertilizer Metric Tonnes but was then converted to urea fertilizer in metric tonnes\n    \n    #-------Arguments--------\n    #input.filename <---- Name of file with activity data, which is a comma delimited (CSV) file\n                          #activity data is in metric tonnes of urea fertilizer\n# EFmean <------- 0.2\n# EFmin <----- 0.1\n# EFmax <----- 0.2\n# nyears <-----31\n# nstates <------ 50\n\n{\n  #set the seed\n  set.seed(iseed)\n  \n  # Load libraries\n  library(triangle)\n  \n  # Import input file\n input.data<-read.csv(file=\"data/Ureafert.csv\", header = TRUE, fill=FALSE)\n  \n  #---------Data Checks---------\n  #\n  # Check that urea amounts are numeric\n  \n  for (n in 1:(nyears*2)){\n    input.data[,n+1] <- as.numeric(input.data[,n+1])\n  }\n  #\n  #Check that SD's are numeric\n  \n  for(n in 1:(nyears*2)){\n    input.data[,n+1]<-as.numeric(input.data[,n+1])\n  }\n  \n  # Validity checks that urea.amount and SD's are within the expected min and max range\n  for(y in (1:nyears)){\n    for(s in (1:nstates)){\n      check.urea.amount <- length(input.data[s,y+1]) > 0 \n      if(!check.urea.amount){stop(\"Warning: Urea amount is not greater than 0\")}\n    }\n        }\n  #\n#---------Deterministic Results--------\n  \n  Deterministic.CO2C.state<-matrix(0, nrow=nstates, ncol=nyears)\n    for(y in (1:nyears)){\n      for(s in (1:nstates)){\n        Deterministic.CO2C.state[s,y]<- input.data[s,(y*2)]*EF.mean\n      }\n    }\n  \n# Sum the state CO2-C emissions for grand totals in each year\n  Deterministic.CO2C.USA<-apply(Deterministic.CO2C.state, MAR=2, FUN=\"sum\")\n\n  \n# Convert state and total CO2-C Emissions (in Metric Tonnes) to CO2e in Gigagrams\n  ### 44/12 converts CO2-C to CO2e\n  ### 10^6 converts metric tonnes to gigagrams\n  Deterministic.CO2C.state<-(Deterministic.CO2C.state*(44/12))/10^6\n  Deterministic.CO2C.USA<-(Deterministic.CO2C.USA*(44/12))/10^6\n  \n#--------Probabilistic Results----------\n  \n#simulate nreps for EFmean\n  ### the EF shows a triangle distribution so there is a min, max, and mean EF\n  \n  EF.sim<-rtriangle(nreps, a=EF.min, b=EF.max, c=EF.mean)\n  \n# Simulate nreps for urea inputs\n  urea.sim<-matrix(0, nrow=nstates*nyears, ncol=nreps)\n  for(y in (1:nyears)){\n    for(s in (1:nstates)){\n      urea.sim[s+((y-1)*50),]<-rnorm(nreps, mean=input.data[s,(y*2)], sd=input.data[s,3+((y-1)*2)])\n    }\n  }\n  \n# Estimate probabilistic results (in CO2-C for individual state totals and then year totals)\n  ### Remember that this is now a triangle distribution, so we need to account for the mode instead of the median\n  \n ### Estimate the state total emissions for each year\n  \n   Probabilistic.CO2C.state<-matrix(0, nrow=nstates*nyears, ncol=nreps)\n  for(y in (1:nyears)){\n    for(s in (1:nstates)){\n      Probabilistic.CO2C.state[s+((y-1)*nstates),]<- EF.sim*urea.sim[s+((y-1)*nstates),]\n    }\n  }\n\n# Sum the US and state totals for all 31 years (remember to convert from metric tonnes to gigagrams 10^6 and convert CO2-C to CO2 44/12)\n  \n### Get the MODE for the states emissions, create mode function\n  mode<-function(x,n=2){\n    x<-round(x,n)\n    u<-unique(x)\n    u[which.max(tabulate(match(x,u)))]\n \n}\n  \n### Sum the probabilistic emissions\n  Probabilistic.CO2C.totalUS<-matrix(0, nrow=nyears, ncol=nreps)\n  for(y in (1:nyears)){\n    Probabilistic.CO2C.totalUS[y,]<-apply(Probabilistic.CO2C.state[(1+(50*(y-1))):(50+(50*(y-1))),], MAR=2, FUN=\"sum\")}\n\n\n  #------US Totals: Estimate mode and confidence intervals--------\n  \n  CO2C.USemission.results<-matrix(0, nrow=nyears, ncol=3)\n  for (y in (1:nyears)){\n    CO2C.USemission.results[y,1]<- mode(Probabilistic.CO2C.totalUS[y,])\n    q<-quantile(Probabilistic.CO2C.totalUS[y,], probs = c(0.05, 1))\n    CO2C.USemission.results[y,2]<- q[1]\n    CO2C.USemission.results[y,3]<- q[2]\n  }\n  \n\n    \n### Convert US total CO2-C Emissions (in Metric Tonnes) to CO2e in Gigagrams\n    ### 44/12 converts CO2-C to CO2e\n    ### 10^6 converts metric tonnes to gigagrams\n    CO2.USemission.results<-(CO2C.USemission.results*(44/12))/10^6\n \n    \n  #------Yearly state totals:Estimate mode and confidence intervals--------\n    \n  CO2C.Stateemission.results<-matrix(0, nrow=nstates*nyears, ncol=3)\n    for(y in (1:(nyears*nstates))){\n      CO2C.Stateemission.results[y,1]<- mode(Probabilistic.CO2C.state[y,])\n      q<-quantile(Probabilistic.CO2C.state[y,], probs = c(0.05, 1))\n      CO2C.Stateemission.results[y,2]<- q[1]\n      CO2C.Stateemission.results[y,3]<- q[2]\n\n    }\n    ### Convert State  CO2-C Emissions (in Metric Tonnes) to CO2e in Gigagrams\n    ### 44/12 converts CO2-C to CO2e\n    ### 10^6 converts metric tonnes to gigagrams\n    CO2.Stateemission.results<-(CO2C.Stateemission.results*(44/12))/10^6\n    \n    #\n    \n  #-----------Return Statement------------\n    \n    ### Total US Results\n    CO2.USemission.results<-CO2.USemission.results\n    colnames(CO2.USemission.results)<-c(\"mode.GgCO2\", \"5  Percentile\", \"100 Percentile\")\n    \n    \n    ### Results by state for each year\n    CO2.Stateemission.results<-CO2.Stateemission.results\n    colnames(State.emission.results)<-c(\"mode.GgCO2\", \"5  Percentile\", \"100 Percentile\")\n    \n    \n    \n    #\n    ###### End Script\n  }\n\n\nFinal_UreaEmission <-UreaEmissionsUS(input.filename=\"data/Ureafert.csv\")"
  }
]